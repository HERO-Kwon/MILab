{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python library\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Animal Class\n",
    "target_animal = 'monkey'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>truth</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monkey/pic1_monkey_white2.gif</td>\n",
       "      <td>0</td>\n",
       "      <td>pic1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>monkey/pic2_logotrans200.gif</td>\n",
       "      <td>0</td>\n",
       "      <td>pic2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monkey/pic3_DesignSurvey.gif</td>\n",
       "      <td>0</td>\n",
       "      <td>pic3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monkey/pic4_Popup.gif</td>\n",
       "      <td>0</td>\n",
       "      <td>pic4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monkey/pic5_Results.gif</td>\n",
       "      <td>0</td>\n",
       "      <td>pic5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  truth    ID\n",
       "0  monkey/pic1_monkey_white2.gif      0  pic1\n",
       "1   monkey/pic2_logotrans200.gif      0  pic2\n",
       "2   monkey/pic3_DesignSurvey.gif      0  pic3\n",
       "3          monkey/pic4_Popup.gif      0  pic4\n",
       "4        monkey/pic5_Results.gif      0  pic5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read ground truth file\n",
    "import scipy.io as sio # Library for .mat files\n",
    "import re # Library for Regular Expression\n",
    "file_path = 'D:\\\\Data\\\\AnimalsOnTheWeb\\\\' + target_animal + '\\\\'\n",
    "file = 'animaldata_'+ target_animal + '.mat'\n",
    "# Read from .mat files\n",
    "data_read = sio.loadmat(os.path.join(file_path,file))\n",
    "\n",
    "# truth table (1 or 0)\n",
    "truth_tbl = list(data_read['gt'][0]) \n",
    "\n",
    "# get picture ID and save it to 'name' column\n",
    "truth_nameread = list(data_read['imgnames'][0])\n",
    "truth_name = [t[0] for t in truth_nameread]\n",
    "truth_lists = pd.DataFrame({'name': truth_name,'truth': truth_tbl})\n",
    "truth_lists['name'] = truth_lists['name'].astype('str')\n",
    "re_picid = re.compile('pic\\d+')\n",
    "truth_lists['ID'] = [re_picid.findall(r)[0] for r in truth_lists['name']]\n",
    "truth_lists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pyspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Session\n",
    "sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read image files in directory and make it to dataframe\n",
    "img_dir = \"D:\\\\Data\\\\AnimalsOnTheWeb\\\\\" + target_animal\n",
    "imgs = spark.read.format(\"image\").load(img_dir)\n",
    "imgs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read feature files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ind: integer (nullable = true)\n",
      " |-- Animal: string (nullable = true)\n",
      " |-- File: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- LBP0: float (nullable = true)\n",
      " |-- LBP1: float (nullable = true)\n",
      " |-- LBP2: float (nullable = true)\n",
      " |-- LBP3: float (nullable = true)\n",
      " |-- LBP4: float (nullable = true)\n",
      " |-- LBP5: float (nullable = true)\n",
      " |-- LBP6: float (nullable = true)\n",
      " |-- LBP7: float (nullable = true)\n",
      " |-- LBP8: float (nullable = true)\n",
      " |-- LBP9: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as typ\n",
    "res_lbp = spark.read.csv('Res_LBP.csv',header=True)\n",
    "labels =[\n",
    "    ('ind',typ.IntegerType()), # index\n",
    "    ('Animal',typ.StringType()), # Class of animals\n",
    "    ('File',typ.StringType()), # filename\n",
    "    ('ID',typ.StringType()), # picture ID\n",
    "    ('LBP0',typ.FloatType()), # LBP features\n",
    "    ('LBP1',typ.FloatType()),\n",
    "    ('LBP2',typ.FloatType()),\n",
    "    ('LBP3',typ.FloatType()),\n",
    "    ('LBP4',typ.FloatType()),\n",
    "    ('LBP5',typ.FloatType()),\n",
    "    ('LBP6',typ.FloatType()),\n",
    "    ('LBP7',typ.FloatType()),\n",
    "    ('LBP8',typ.FloatType()),\n",
    "    ('LBP9',typ.FloatType()),\n",
    "]\n",
    "# Define Schema\n",
    "schema = typ.StructType([\n",
    "    typ.StructField(e[0],e[1],False) for e in labels\n",
    "])\n",
    "\n",
    "# CSV read\n",
    "res_lbp = spark.read.csv('Res_LBP.csv',header=True,schema=schema)\n",
    "res_lbp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select animal to classify\n",
    "target_lbp = res_lbp.where(res_lbp.Animal.isin(target_animal)) # only alligator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- truth: long (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pandas Dataframe to Spark Dataframe\n",
    "df_truth = spark.createDataFrame(truth_lists)\n",
    "df_truth.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='monkey/pic1_monkey_white2.gif', truth=0, ID='pic1'),\n",
       " Row(name='monkey/pic2_logotrans200.gif', truth=0, ID='pic2'),\n",
       " Row(name='monkey/pic3_DesignSurvey.gif', truth=0, ID='pic3'),\n",
       " Row(name='monkey/pic4_Popup.gif', truth=0, ID='pic4'),\n",
       " Row(name='monkey/pic5_Results.gif', truth=0, ID='pic5')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show 5 row\n",
    "df_truth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- truth: long (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- truth_int: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cast Truth column to integer\n",
    "df_truth = df_truth.withColumn('truth_int',df_truth['truth'].cast(typ.IntegerType()))\n",
    "df_truth.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- truth: long (nullable = true)\n",
      " |-- truth_int: integer (nullable = true)\n",
      " |-- ind: integer (nullable = true)\n",
      " |-- Animal: string (nullable = true)\n",
      " |-- File: string (nullable = true)\n",
      " |-- LBP0: float (nullable = true)\n",
      " |-- LBP1: float (nullable = true)\n",
      " |-- LBP2: float (nullable = true)\n",
      " |-- LBP3: float (nullable = true)\n",
      " |-- LBP4: float (nullable = true)\n",
      " |-- LBP5: float (nullable = true)\n",
      " |-- LBP6: float (nullable = true)\n",
      " |-- LBP7: float (nullable = true)\n",
      " |-- LBP8: float (nullable = true)\n",
      " |-- LBP9: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ml = df_truth.join(target_lbp,on='ID')\n",
    "df_ml.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Feature and result column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml1 = df_ml.select([c for c in df_ml.columns if c in ['truth_int','LBP0','LBP1','LBP2','LBP3','LBP4','LBP5','LBP6','LBP7','LBP8','LBP9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- truth_int: integer (nullable = true)\n",
      " |-- LBP0: float (nullable = true)\n",
      " |-- LBP1: float (nullable = true)\n",
      " |-- LBP2: float (nullable = true)\n",
      " |-- LBP3: float (nullable = true)\n",
      " |-- LBP4: float (nullable = true)\n",
      " |-- LBP5: float (nullable = true)\n",
      " |-- LBP6: float (nullable = true)\n",
      " |-- LBP7: float (nullable = true)\n",
      " |-- LBP8: float (nullable = true)\n",
      " |-- LBP9: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ml1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Feature column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 =[\n",
    "    ('LBP0',typ.FloatType()),\n",
    "    ('LBP1',typ.FloatType()),\n",
    "    ('LBP2',typ.FloatType()),\n",
    "    ('LBP3',typ.FloatType()),\n",
    "    ('LBP4',typ.FloatType()),\n",
    "    ('LBP5',typ.FloatType()),\n",
    "    ('LBP6',typ.FloatType()),\n",
    "    ('LBP7',typ.FloatType()),\n",
    "    ('LBP8',typ.FloatType()),\n",
    "    ('LBP9',typ.FloatType()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresCreator = ft.VectorAssembler(\n",
    "    inputCols=[col[0] for col in labels1[0:]],outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.classification as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = cl.LogisticRegression(maxIter=10,regParam=0.01,labelCol='truth_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[featuresCreator,logistic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and test data\n",
    "lbp_train, lbp_test = df_ml1.randomSplit([0.7,0.3],seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(lbp_train) #train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(truth_int=0, LBP0=0.0, LBP1=0.0, LBP2=0.0, LBP3=0.0, LBP4=0.0, LBP5=0.0, LBP6=0.0, LBP7=0.0, LBP8=0.0, LBP9=0.0, features=SparseVector(10, {}), rawPrediction=DenseVector([2.4983, -2.4983]), probability=DenseVector([0.924, 0.076]), prediction=0.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = model.transform(lbp_test) # get results on test dataset\n",
    "test_model.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.evaluation as ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.8494523973784067\n"
     ]
    }
   ],
   "source": [
    "evaluator = ev.BinaryClassificationEvaluator(rawPredictionCol='probability',labelCol='truth_int')\n",
    "print('Area under ROC curve: ' + str(evaluator.evaluate(test_model, {evaluator.metricName:'areaUnderROC'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.clustering as clus\n",
    "kmeans = clus.KMeans(k=10, featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[featuresCreator,kmeans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_km = res_lbp.select([c for c in df_ml.columns if c in ['LBP0','LBP1','LBP2','LBP3','LBP4','LBP5','LBP6','LBP7','LBP8','LBP9']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and test data\n",
    "km_train, km_test = df_km.randomSplit([0.7,0.3],seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_km = pipeline.fit(km_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_km = model_km.transform(km_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=1, avg(LBP1)=0.006628613927448388, avg(LBP0)=0.004168090764472063, count(1)=258),\n",
       " Row(prediction=6, avg(LBP1)=0.05245462622073535, avg(LBP0)=0.03945028164768144, count(1)=479),\n",
       " Row(prediction=3, avg(LBP1)=0.06755132657004359, avg(LBP0)=0.05124026305691833, count(1)=162),\n",
       " Row(prediction=5, avg(LBP1)=0.019706812097173957, avg(LBP0)=0.0134566055527327, count(1)=405),\n",
       " Row(prediction=9, avg(LBP1)=0.06786785193954606, avg(LBP0)=0.05170888021909987, count(1)=498),\n",
       " Row(prediction=4, avg(LBP1)=0.10401775009862664, avg(LBP0)=0.10296872409029272, count(1)=773),\n",
       " Row(prediction=8, avg(LBP1)=0.0, avg(LBP0)=0.0, count(1)=92),\n",
       " Row(prediction=7, avg(LBP1)=0.08957870951917984, avg(LBP0)=0.07801360607926075, count(1)=1014),\n",
       " Row(prediction=2, avg(LBP1)=0.03819214777923752, avg(LBP0)=0.028137821773230865, count(1)=364),\n",
       " Row(prediction=0, avg(LBP1)=0.06482088577467948, avg(LBP0)=0.051403644548626004, count(1)=488)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_km.groupBy('prediction').agg({'*':'count','LBP0':'avg','LBP1':'avg'}).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
