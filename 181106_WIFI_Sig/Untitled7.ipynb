{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread(img_path+img_list[0], 0)\n",
    "# Thresholding the image\n",
    "(thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "cv2.THRESH_BINARY,15,15)\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "cv2.THRESH_BINARY,15,15)\n",
    "# Invert the image\n",
    "#img_bin = 255-img_bin \n",
    "img_bin = 255-th2\n",
    "cv2.imwrite(\"Image_bin2.jpg\",255-th2)\n",
    "cv2.imwrite(\"Image_bin3.jpg\",255-th3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a kernel length\n",
    "kernel_length = np.array(img).shape[1]//80\n",
    " \n",
    "# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "# A kernel of (3 X 3) ones.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological operation to detect vertical lines from an image\n",
    "img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "# Morphological operation to detect horizontal lines from an image\n",
    "img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "alpha = 0.5\n",
    "beta = 1.0 - alpha\n",
    "# This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "(thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours for image, which will detect all the boxes\n",
    "im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Sort all the contours by top to bottom.\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "\t# initialize the reverse flag and sort index\n",
    "\treverse = False\n",
    "\ti = 0\n",
    " \n",
    "\t# handle if we need to sort in reverse\n",
    "\tif method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "\t\treverse = True\n",
    " \n",
    "\t# handle if we are sorting against the y-coordinate rather than\n",
    "\t# the x-coordinate of the bounding box\n",
    "\tif method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "\t\ti = 1\n",
    " \n",
    "\t# construct the list of bounding boxes and sort them from top to\n",
    "\t# bottom\n",
    "\tboundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "\t(cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "\t\tkey=lambda b:b[1][i], reverse=reverse))\n",
    " \n",
    "\t# return the list of sorted contours and bounding boxes\n",
    "\treturn (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    idx = 0\n",
    "    ori_shape = img_bin.shape\n",
    "    bias = 5 # to remove box line\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if (w > ori_shape[0]/20 and h > ori_shape[1]/20) and 10*w*h < ori_shape[0]*ori_shape[1]:\n",
    "            idx += 1\n",
    "            new_img = img[y+bias:y+h-bias, x+bias:x+w-bias]\n",
    "            cv2.imwrite(str(idx) + '.png', 255-new_img)\n",
    "        '''    \n",
    "# If the box height is greater then 20, widht is >80, then only save it as a box in \"cropped/\" folder.\n",
    "        if (w > 80 and h > 20) and w > 3*h:\n",
    "            idx += 1\n",
    "            new_img = img[y:y+h, x:x+w]\n",
    "            cv2.imwrite(str(idx) + '.png', new_img)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w*h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th3.shape[0]*th3.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(th3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(img_path+img_list[41], 0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "e = cv2.erode(img,kernel,iterations = 2)  \n",
    "d = cv2.dilate(e,kernel,iterations = 1)\n",
    "\n",
    "# Thresholding the image\n",
    "(thresh, img_bin) = cv2.threshold(d, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "th2 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "cv2.THRESH_BINARY,15,15)\n",
    "th3 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "cv2.THRESH_BINARY,15,15)\n",
    "# Invert the image\n",
    "#img_bin = 255-img_bin \n",
    "img_bin = 255-th2\n",
    "cv2.imwrite(\"Image_bin_d.jpg\",img_bin)\n",
    "#cv2.imwrite(\"Image_bin3.jpg\",255-th3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a kernel length\n",
    "kernel_length = np.array(img).shape[1]//80\n",
    " \n",
    "# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "# A kernel of (3 X 3) ones.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "# Morphological operation to detect vertical lines from an image\n",
    "img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "#cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "# Morphological operation to detect horizontal lines from an image\n",
    "img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "#cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "# Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "alpha = 0.5\n",
    "beta = 1.0 - alpha\n",
    "# This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "(thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "# Find contours for image, which will detect all the boxes\n",
    "im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Sort all the contours by top to bottom.\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "\t# initialize the reverse flag and sort index\n",
    "\treverse = False\n",
    "\ti = 0\n",
    " \n",
    "\t# handle if we need to sort in reverse\n",
    "\tif method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "\t\treverse = True\n",
    " \n",
    "\t# handle if we are sorting against the y-coordinate rather than\n",
    "\t# the x-coordinate of the bounding box\n",
    "\tif method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "\t\ti = 1\n",
    " \n",
    "\t# construct the list of bounding boxes and sort them from top to\n",
    "\t# bottom\n",
    "\tboundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "\t(cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "\t\tkey=lambda b:b[1][i], reverse=reverse))\n",
    " \n",
    "\t# return the list of sorted contours and bounding boxes\n",
    "\treturn (cnts, boundingBoxes)\n",
    "\n",
    "idx = 0\n",
    "ori_shape = img_bin.shape\n",
    "bias_x = 17 # to remove box line\n",
    "bias_y = 20 # to remove box line\n",
    "for c in contours:\n",
    "    # Returns the location and width,height for every contour\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if (w > ori_shape[0]/20 and h > ori_shape[1]/20) and 10*w*h < ori_shape[0]*ori_shape[1]:\n",
    "        idx += 1\n",
    "        new_img = img[y+bias_y:y+h-bias_y, x+bias_x:x+w-bias_x]\n",
    "        resized_img = new_img.resize((625,375))\n",
    "        cv2.imwrite(str(idx) + '.png', new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = cv2.rotate(img_bin,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"aa.jpg\",aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center=tuple(np.array(img_bin.shape[0:2])/2)\n",
    "rot_mat = cv2.getRotationMatrix2D(center,90,1.0)\n",
    "aa = cv2.warpAffine(img_bin, rot_mat, img_bin.shape[0:2],flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"aa.jpg\",aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(img_path+img_list[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = cv2.resize(new_img,(625,375))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)\n",
    "\n",
    "#for img_sign in img_list:\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(img_path+img_list[0], 0)\n",
    "\n",
    "# Rotate\n",
    "if img.shape[0] < img.shape[1]:\n",
    "    center=tuple(np.array(img.shape[0:2])/2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(center,270,1.0)\n",
    "    img = cv2.warpAffine(img, rot_mat, img.shape[0:2],flags=cv2.INTER_LINEAR)\n",
    "\n",
    "#elode,dilate\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "e = cv2.erode(img,kernel,iterations = 2)  \n",
    "d = cv2.dilate(e,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "# Thresholding the image\n",
    "(thresh, img_bin) = cv2.threshold(d, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "th2 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "cv2.THRESH_BINARY,15,15)\n",
    "th3 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "cv2.THRESH_BINARY,15,15)\n",
    "# Invert the image\n",
    "#img_bin = 255-img_bin \n",
    "img_bin = 255-th2\n",
    "#cv2.imwrite(\"Image_bin2.jpg\",255-th2)\n",
    "#cv2.imwrite(\"Image_bin3.jpg\",255-th3)\n",
    "\n",
    "# Defining a kernel length\n",
    "kernel_length = np.array(img).shape[1]//80\n",
    " \n",
    "# A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "# A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "# A kernel of (3 X 3) ones.\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "# Morphological operation to detect vertical lines from an image\n",
    "img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "#cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "# Morphological operation to detect horizontal lines from an image\n",
    "img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "#cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "# Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "alpha = 0.5\n",
    "beta = 1.0 - alpha\n",
    "# This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "(thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "#cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "# Find contours for image, which will detect all the boxes\n",
    "im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Sort all the contours by top to bottom.\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "\t# initialize the reverse flag and sort index\n",
    "\treverse = False\n",
    "\ti = 0\n",
    " \n",
    "\t# handle if we need to sort in reverse\n",
    "\tif method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "\t\treverse = True\n",
    " \n",
    "\t# handle if we are sorting against the y-coordinate rather than\n",
    "\t# the x-coordinate of the bounding box\n",
    "\tif method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "\t\ti = 1\n",
    " \n",
    "\t# construct the list of bounding boxes and sort them from top to\n",
    "\t# bottom\n",
    "\tboundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "\t(cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "\t\tkey=lambda b:b[1][i], reverse=reverse))\n",
    " \n",
    "\t# return the list of sorted contours and bounding boxes\n",
    "\treturn (cnts, boundingBoxes)\n",
    "\n",
    "idx = 0\n",
    "ori_shape = img_bin.shape\n",
    "bias_x = 20 # to remove box line\n",
    "bias_y = 17 # to remove box line\n",
    "for c in contours:\n",
    "    # Returns the location and width,height for every contour\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if (w > ori_shape[0]/20 and h > ori_shape[1]/20) and 10*w*h < ori_shape[0]*ori_shape[1]:\n",
    "        idx += 1\n",
    "        new_img = img[y+bias_y:y+h-bias_y, x+bias_x:x+w-bias_x]\n",
    "        resized_img = cv2.resize(new_img,(625,375))\n",
    "        cv2.imwrite(str(idx) + '.png', new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)\n",
    "save_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature_processed\\\\'\n",
    "\n",
    "for img_sign in img_list:\n",
    "\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path+img_sign, 0)\n",
    "\n",
    "    # Rotate\n",
    "    if img.shape[0] > img.shape[1]:\n",
    "        center=tuple(np.array(img.shape[0:2])/2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(center,90,1.0)\n",
    "        img = cv2.warpAffine(img, rot_mat, img.shape[0:2],flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #elode,dilate\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    e = cv2.erode(img,kernel,iterations = 2)  \n",
    "    d = cv2.dilate(e,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "    # Thresholding the image\n",
    "    (thresh, img_bin) = cv2.threshold(d, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "    th2 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    th3 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    # Invert the image\n",
    "    #img_bin = 255-img_bin \n",
    "    img_bin = 255-th2\n",
    "    #cv2.imwrite(\"Image_bin2.jpg\",255-th2)\n",
    "    #cv2.imwrite(\"Image_bin3.jpg\",255-th3)\n",
    "\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//80\n",
    "    \n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    #cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    def sort_contours(cnts, method=\"left-to-right\"):\n",
    "        # initialize the reverse flag and sort index\n",
    "        reverse = False\n",
    "        i = 0\n",
    "    \n",
    "        # handle if we need to sort in reverse\n",
    "        if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "            reverse = True\n",
    "    \n",
    "        # handle if we are sorting against the y-coordinate rather than\n",
    "        # the x-coordinate of the bounding box\n",
    "        if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "            i = 1\n",
    "    \n",
    "        # construct the list of bounding boxes and sort them from top to\n",
    "        # bottom\n",
    "        boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "            key=lambda b:b[1][i], reverse=reverse))\n",
    "    \n",
    "        # return the list of sorted contours and bounding boxes\n",
    "        return (cnts, boundingBoxes)\n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "    \n",
    "    idx = 0\n",
    "    ori_shape = img_bin.shape\n",
    "    bias_x = 17 # to remove box line\n",
    "    bias_y = 20 # to remove box line\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if (w > ori_shape[0]/20 and h > ori_shape[1]/20) and 10*w*h < ori_shape[0]*ori_shape[1]:\n",
    "            idx += 1\n",
    "            new_img = img[y+bias_y:y+h-bias_y, x+bias_x:x+w-bias_x]\n",
    "            resized_img = cv2.resize(new_img,(625,375))\n",
    "            cv2.imwrite(save_path+img_sign+str(idx) + '.png', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.search('IMG_\\d+',img_list[0]).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)\n",
    "save_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature_processed\\\\'\n",
    "\n",
    "for img_sign in img_list:\n",
    "    img_name = re.search('IMG_\\d+',img_list[0]).group(0)\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path+img_sign, 0)\n",
    "\n",
    "    # Rotate\n",
    "    if img.shape[0] > img.shape[1]:\n",
    "        center=tuple(np.array(img.shape[0:2])/2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(center,270,1.0)\n",
    "        img = cv2.warpAffine(img, rot_mat, img.shape[0:2],flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #elode,dilate\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    e = cv2.erode(img,kernel,iterations = 2)  \n",
    "    d = cv2.dilate(e,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "    # Thresholding the image\n",
    "    (thresh, img_bin) = cv2.threshold(d, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "    th2 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    th3 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    # Invert the image\n",
    "    #img_bin = 255-img_bin \n",
    "    img_bin = 255-th2\n",
    "    #cv2.imwrite(\"Image_bin2.jpg\",255-th2)\n",
    "    #cv2.imwrite(\"Image_bin3.jpg\",255-th3)\n",
    "\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//80\n",
    "    \n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    #cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    def sort_contours(cnts, method=\"left-to-right\"):\n",
    "        # initialize the reverse flag and sort index\n",
    "        reverse = False\n",
    "        i = 0\n",
    "    \n",
    "        # handle if we need to sort in reverse\n",
    "        if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "            reverse = True\n",
    "    \n",
    "        # handle if we are sorting against the y-coordinate rather than\n",
    "        # the x-coordinate of the bounding box\n",
    "        if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "            i = 1\n",
    "    \n",
    "        # construct the list of bounding boxes and sort them from top to\n",
    "        # bottom\n",
    "        boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "            key=lambda b:b[1][i], reverse=reverse))\n",
    "    \n",
    "        # return the list of sorted contours and bounding boxes\n",
    "        return (cnts, boundingBoxes)\n",
    "    \n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "\n",
    "    idx = 0\n",
    "    ori_shape = img_bin.shape\n",
    "    bias_x = 17 # to remove box line\n",
    "    bias_y = 20 # to remove box line\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if (w > ori_shape[0]/20 and h > ori_shape[1]/20) and 10*w*h < ori_shape[0]*ori_shape[1]:\n",
    "            idx += 1\n",
    "            new_img = img[y+bias_y:y+h-bias_y, x+bias_x:x+w-bias_x]\n",
    "            resized_img = cv2.resize(new_img,(375,625))\n",
    "            cv2.imwrite(save_path+img_name+'_'+str(idx) + '.png', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    img_name = re.search('IMG_\\d+',img_list[0]).group(0)\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path+img_sign, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Rotate\n",
    "    if img.shape[0] > img.shape[1]:\n",
    "        center=tuple(np.array(img.shape[0:2])/2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(center,270,1.0)\n",
    "        img = cv2.warpAffine(img, rot_mat, img.shape[0:2],flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img = cv2.resize(new_img,(375,625))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)\n",
    "save_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature_processed\\\\'\n",
    "\n",
    "for img_sign in img_list:\n",
    "    img_name = re.search('IMG_\\d+',img_sign).group(0)\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path+img_sign, 0)\n",
    "\n",
    "    # Rotate\n",
    "    if img.shape[0] > img.shape[1]:\n",
    "        center=tuple(np.array(img.shape[0:2])/2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(center,270,1.0)\n",
    "        img = cv2.warpAffine(img, rot_mat, img.shape[0:2],flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #elode,dilate\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    e = cv2.erode(img,kernel,iterations = 2)  \n",
    "    d = cv2.dilate(e,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "    # Thresholding the image\n",
    "    (thresh, img_bin) = cv2.threshold(d, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "    th2 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    th3 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    # Invert the image\n",
    "    #img_bin = 255-img_bin \n",
    "    img_bin = 255-th2\n",
    "    #cv2.imwrite(\"Image_bin2.jpg\",255-th2)\n",
    "    #cv2.imwrite(\"Image_bin3.jpg\",255-th3)\n",
    "\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//80\n",
    "    \n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    #cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    def sort_contours(cnts, method=\"left-to-right\"):\n",
    "        # initialize the reverse flag and sort index\n",
    "        reverse = False\n",
    "        i = 0\n",
    "    \n",
    "        # handle if we need to sort in reverse\n",
    "        if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "            reverse = True\n",
    "    \n",
    "        # handle if we are sorting against the y-coordinate rather than\n",
    "        # the x-coordinate of the bounding box\n",
    "        if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "            i = 1\n",
    "    \n",
    "        # construct the list of bounding boxes and sort them from top to\n",
    "        # bottom\n",
    "        boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "            key=lambda b:b[1][i], reverse=reverse))\n",
    "    \n",
    "        # return the list of sorted contours and bounding boxes\n",
    "        return (cnts, boundingBoxes)\n",
    "    \n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "\n",
    "    idx = 0\n",
    "    ori_shape = img_bin.shape\n",
    "    bias_x = 17 # to remove box line\n",
    "    bias_y = 20 # to remove box line\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if (w > 600 and h > 300) and 24*w*h < ori_shape[0]*ori_shape[1]:\n",
    "            idx += 1\n",
    "            new_img = img[y+bias_y:y+h-bias_y, x+bias_x:x+w-bias_x]\n",
    "            resized_img = cv2.resize(new_img,(625,375))\n",
    "            cv2.imwrite(save_path+img_name+'_'+str(idx) + '.png', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(save_path+img_name+'_'+str(idx) + '.png', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            resized_img = cv2.resize(new_img,(625,375))\n",
    "            cv2.imwrite(save_path+img_name+'_'+str(idx) + '.png', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)\n",
    "save_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature_processed\\\\'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sign = img_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    img_name = re.search('IMG_\\d+',img_sign).group(0)\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path+img_sign, 0)\n",
    "\n",
    "    # Rotate\n",
    "    if img.shape[0] < img.shape[1]:\n",
    "        center=tuple(np.array(img.shape[0:2])/2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(center,270,1.0)\n",
    "        img = cv2.warpAffine(img, rot_mat, img.shape[0:2],flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #elode,dilate\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    e = cv2.erode(img,kernel,iterations = 2)  \n",
    "    d = cv2.dilate(e,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "    # Thresholding the image\n",
    "    (thresh, img_bin) = cv2.threshold(d, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "    th2 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    th3 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    # Invert the image\n",
    "    #img_bin = 255-img_bin \n",
    "    img_bin = 255-th2\n",
    "    cv2.imwrite(\"Image_bin2.jpg\",255-th2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//80\n",
    "    \n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    def sort_contours(cnts, method=\"left-to-right\"):\n",
    "        # initialize the reverse flag and sort index\n",
    "        reverse = False\n",
    "        i = 0\n",
    "    \n",
    "        # handle if we need to sort in reverse\n",
    "        if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "            reverse = True\n",
    "    \n",
    "        # handle if we are sorting against the y-coordinate rather than\n",
    "        # the x-coordinate of the bounding box\n",
    "        if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "            i = 1\n",
    "    \n",
    "        # construct the list of bounding boxes and sort them from top to\n",
    "        # bottom\n",
    "        boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "            key=lambda b:b[1][i], reverse=reverse))\n",
    "    \n",
    "        # return the list of sorted contours and bounding boxes\n",
    "        return (cnts, boundingBoxes)\n",
    "    \n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method=\"left-to-right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    idx = 0\n",
    "    ori_shape = img_bin.shape\n",
    "    bias_x = 20 # to remove box line\n",
    "    bias_y = 17 # to remove box line\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if (w > 300 and h > 150) and 10*w*h < ori_shape[0]*ori_shape[1]:\n",
    "            idx += 1\n",
    "            new_img = img[y+bias_y:y+h-bias_y, x+bias_x:x+w-bias_x]\n",
    "            resized_img = cv2.resize(new_img,(625,375))\n",
    "            cv2.imwrite(save_path+img_name+'_'+str(idx) + '.png', new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    img_name = re.search('IMG_\\d+',img_sign).group(0)\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path+img_sign, 0)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "img_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature\\\\'\n",
    "img_list = os.listdir(img_path)\n",
    "save_path = 'D:\\Matlab_Drive\\Data\\WIFI\\Image\\Signature_processed\\\\'\n",
    "\n",
    "for img_sign in img_list:\n",
    "    img_name = re.search('IMG_\\d+',img_sign).group(0)\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path+img_sign, 0)\n",
    "\n",
    "    # Rotate\n",
    "    if img.shape[0] < img.shape[1]:\n",
    "        center=tuple(np.array(img.shape[0:2])/2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(center,270,1.0)\n",
    "        img = cv2.warpAffine(img, rot_mat, img.shape[0:2],flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    #elode,dilate\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    e = cv2.erode(img,kernel,iterations = 2)  \n",
    "    d = cv2.dilate(e,kernel,iterations = 1)\n",
    "\n",
    "\n",
    "    # Thresholding the image\n",
    "    (thresh, img_bin) = cv2.threshold(d, 128, 255,cv2.THRESH_BINARY|     cv2.THRESH_OTSU)\n",
    "    th2 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    th3 = cv2.adaptiveThreshold(d,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "    cv2.THRESH_BINARY,15,15)\n",
    "    # Invert the image\n",
    "    #img_bin = 255-img_bin \n",
    "    img_bin = 255-th2\n",
    "    #cv2.imwrite(\"Image_bin2.jpg\",255-th2)\n",
    "\n",
    "    # Defining a kernel length\n",
    "    kernel_length = np.array(img).shape[1]//80\n",
    "    \n",
    "    # A verticle kernel of (1 X kernel_length), which will detect all the verticle lines from the image.\n",
    "    verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, kernel_length))\n",
    "    # A horizontal kernel of (kernel_length X 1), which will help to detect all the horizontal line from the image.\n",
    "    hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "    # A kernel of (3 X 3) ones.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    # Morphological operation to detect vertical lines from an image\n",
    "    img_temp1 = cv2.erode(img_bin, verticle_kernel, iterations=3)\n",
    "    verticle_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"verticle_lines.jpg\",verticle_lines_img)\n",
    "    # Morphological operation to detect horizontal lines from an image\n",
    "    img_temp2 = cv2.erode(img_bin, hori_kernel, iterations=3)\n",
    "    horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
    "    #cv2.imwrite(\"horizontal_lines.jpg\",horizontal_lines_img)\n",
    "\n",
    "    # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
    "    img_final_bin = cv2.addWeighted(verticle_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
    "    img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
    "    (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    #cv2.imwrite(\"img_final_bin.jpg\",img_final_bin)\n",
    "\n",
    "    # Find contours for image, which will detect all the boxes\n",
    "    im2, contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    def sort_contours(cnts, method=\"left-to-right\"):\n",
    "        # initialize the reverse flag and sort index\n",
    "        reverse = False\n",
    "        i = 0\n",
    "    \n",
    "        # handle if we need to sort in reverse\n",
    "        if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "            reverse = True\n",
    "    \n",
    "        # handle if we are sorting against the y-coordinate rather than\n",
    "        # the x-coordinate of the bounding box\n",
    "        if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "            i = 1\n",
    "    \n",
    "        # construct the list of bounding boxes and sort them from top to\n",
    "        # bottom\n",
    "        boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "        (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "            key=lambda b:b[1][i], reverse=reverse))\n",
    "    \n",
    "        # return the list of sorted contours and bounding boxes\n",
    "        return (cnts, boundingBoxes)\n",
    "    \n",
    "    # Sort all the contours by top to bottom.\n",
    "    (contours, boundingBoxes) = sort_contours(contours, method=\"left-to-right\")\n",
    "    idx = 0\n",
    "    ori_shape = img_bin.shape\n",
    "    bias_x = 20 # to remove box line\n",
    "    bias_y = 17 # to remove box line\n",
    "    for c in contours:\n",
    "        # Returns the location and width,height for every contour\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if (w > 300 and h > 150) and 15*w*h < ori_shape[0]*ori_shape[1]:\n",
    "            idx += 1\n",
    "            new_img = img[y+bias_y:y+h-bias_y, x+bias_x:x+w-bias_x]\n",
    "            resized_img = cv2.resize(new_img,(625,375))\n",
    "            cv2.imwrite(save_path+img_name+'_'+str(idx) + '.png', resized_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
