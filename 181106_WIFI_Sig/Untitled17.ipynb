{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN4_JS(in_data):\n",
    "    input2d = tf.reshape(in_data, [-1,max_len,30,6])\n",
    "    conv11 = tf.layers.conv2d(\n",
    "        inputs=input2d, \n",
    "        filters=32, \n",
    "        kernel_size=[3, 3], \n",
    "        strides=2,\n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    conv12 = tf.layers.conv2d(\n",
    "        inputs=conv11, \n",
    "        filters=64, \n",
    "        kernel_size=[3, 3], \n",
    "        strides=2,\n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    conv21 = tf.layers.conv2d(\n",
    "        inputs=conv12, \n",
    "        filters=128, \n",
    "        kernel_size=[3, 3], \n",
    "        strides=1,\n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    conv22 = tf.layers.conv2d(\n",
    "        inputs=conv21, \n",
    "        filters=256, \n",
    "        kernel_size=[3, 3], \n",
    "        strides=2,\n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    bn2 = tf.contrib.layers.batch_norm(conv22, center=True, scale=True, \n",
    "                                          is_training=True\n",
    "                                          )\n",
    "    conv31 = tf.layers.conv2d(\n",
    "        inputs=bn2, \n",
    "        filters=256, \n",
    "        kernel_size=[3, 3], \n",
    "        strides=1,\n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    bn31 = tf.contrib.layers.batch_norm(conv31, center=True, scale=True, \n",
    "                                          is_training=True\n",
    "                                          )\n",
    "    conv32 = tf.layers.conv2d(\n",
    "        inputs=bn31, \n",
    "        filters=256, \n",
    "        kernel_size=[3, 3], \n",
    "        strides=2,\n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    bn32 = tf.contrib.layers.batch_norm(conv32, center=True, scale=True, \n",
    "                                          is_training=True)\n",
    "    conv41 = tf.layers.conv2d(\n",
    "        inputs=bn32, \n",
    "        filters=512, \n",
    "        kernel_size=[3, 3], \n",
    "        strides=1,\n",
    "        padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    pool_flat = tf.reshape(conv41,[-1,32*2*512])#tf.layers.flatten(conv41)\n",
    "    fc = tf.layers.dense(\n",
    "        inputs= pool_flat, units=512, activation=tf.nn.relu)\n",
    "    output = tf.layers.dense(inputs=fc, units=max_id+1)    \n",
    "    return output\n",
    "def CNNmodel(in_data):\n",
    "    input2d = tf.reshape(in_data, [-1,max_len,30,6])\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input2d, \n",
    "        filters=20, \n",
    "        kernel_size=[5, 5], \n",
    "        strides=1,\n",
    "        #padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv1, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2)\n",
    "        #padding=\"same\")\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1, \n",
    "        filters=50, \n",
    "        kernel_size=[5, 5], \n",
    "        strides=1,\n",
    "        #padding=\"same\", \n",
    "        activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, \n",
    "        pool_size=[2, 2], \n",
    "        strides=2)\n",
    "        #padding=\"same\")\n",
    "    #pool_flat = tf.reshape(pool2, [-1, 4 * 4 * 50])\n",
    "    pool_flat = tf.layers.flatten(pool2)\n",
    "    fc = tf.layers.dense(\n",
    "        inputs= pool_flat, units=500, activation=tf.nn.relu)\n",
    "    output = tf.layers.dense(inputs=fc, units=max_id)    \n",
    "    return output\n",
    "\n",
    "def CNN_keras(in_data):\n",
    "    input2d = tf.reshape(in_data, [-1,max_len,30,6])\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input2d, \n",
    "        filters=64, \n",
    "        kernel_size=[3, 3], \n",
    "        #padding=\"same\", \n",
    "        activation=tf.nn.relu)    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=conv1, \n",
    "        filters=128, \n",
    "        kernel_size=[3, 3],\n",
    "        #padding=\"same\", \n",
    "        activation=tf.nn.relu)     \n",
    "    pool1 = tf.layers.max_pooling2d(\n",
    "        inputs=conv2, \n",
    "        pool_size=[2, 2],\n",
    "        strides=1)\n",
    "        #padding=\"same\")    \n",
    "    dropout1 = tf.layers.dropout(\n",
    "        inputs=pool1,\n",
    "        rate=0.3)\n",
    "    pool_flat = tf.layers.flatten(dropout1)\n",
    "    fc = tf.layers.dense(\n",
    "        inputs= pool_flat, units=128, activation=tf.nn.relu)\n",
    "    dropout2 = tf.layers.dropout(\n",
    "        inputs=fc,\n",
    "        rate=0.3)\n",
    "    output = tf.layers.dense(inputs=dropout2, units=max_id)     \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herok\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data path\n",
    "path_csi =  'J:\\\\Data\\\\Wi-Fi_processed\\\\'\n",
    "path_csi_hc = 'J:\\\\Data\\\\Wi-Fi_HC\\\\180_100\\\\'\n",
    "\n",
    "# data info\n",
    "df_info = pd.read_csv('data_subc_sig.csv')\n",
    "\n",
    "# parameters\n",
    "max_id = np.max(df_info['id_person'])\n",
    "no_classes = max_id\n",
    "#max_len = int(np.max(df_info['len']))\n",
    "max_len = 500\n",
    "learning_rate = 0.1\n",
    "training_epochs = 10000\n",
    "batch_size = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(path_csi_hc)\n",
    "file = file_list[0]\n",
    "data_read = np.load(path_csi_hc + file)\n",
    "\n",
    "#filter outliers\n",
    "xs_med = np.median(np.abs(data_read[:,4:]))\n",
    "xs_std = np.std(np.abs(data_read[:,4:]))\n",
    "xs_th = xs_med+xs_std\n",
    "\n",
    "data_read_f =  np.array([row for row in list(data_read) if np.max(np.abs(row[4:])) <= xs_th])\n",
    "\n",
    "# train test split\n",
    "data_tr,data_te = train_test_split(data_read_f,test_size=0.2,random_state=10)\n",
    "#input data\n",
    "data_xs_tr = data_tr[:,4:].astype('float32') / xs_th\n",
    "data_xs_te = data_te[:,4:].astype('float32') / xs_th\n",
    "data_y_tr = data_tr[:,0].astype('int')\n",
    "data_y_te = data_te[:,0].astype('int')\n",
    "\n",
    "x_train = data_xs_tr.reshape([-1,500,30,6])\n",
    "x_test = data_xs_te.reshape([-1,500,30,6])\n",
    "y_train =  tf.keras.utils.to_categorical(data_y_tr, no_classes)\n",
    "y_test =  tf.keras.utils.to_categorical(data_y_te, no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = data_read[data_read[:,0] <10]\n",
    "#a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training datasets\n",
    "dx_train = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "# apply a one-hot transformation to each label for use in the neural network\n",
    "dy_train = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "# zip the x and y training data together and shuffle, batch etc.\n",
    "train_dataset = tf.data.Dataset.zip((dx_train, dy_train)).shuffle(50).repeat().batch(10)\n",
    "\n",
    "# create general iterator\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types,train_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# make datasets that we can initialize separately, but using the same structure via the common iterator\n",
    "training_init_op = iterator.make_initializer(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "logits = CNN_keras(next_element[0])\n",
    "labels_y = next_element[1]\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=logits, labels=labels_y))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    # Ensures that we execute the update_ops before performing the train_step\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "# accuracy\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_pred'):\n",
    "        pred = tf.argmax(logits,1)\n",
    "        equal = tf.equal(pred,tf.argmax(labels_y,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(equal,tf.float32))\n",
    "tf.summary.scalar('accuracy',accuracy)\n",
    "\n",
    "#init\n",
    "init_op = tf.global_variables_initializer()\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "merged_summary_operation = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21 21 21 21 21 21 21 21 90 21]\n",
      "Epoch: 1, loss: 4.699, training accuracy: 0.00%\n",
      "[54 54 54 54 54 54 54 54 54 54]\n",
      "Epoch: 2, loss: 12277789.000, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 3, loss: 507331.250, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 4, loss: 5203841.500, training accuracy: 0.00%\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Epoch: 5, loss: 321672.562, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 6, loss: 317702.312, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 7, loss: 108006.172, training accuracy: 0.00%\n",
      "[51 51 51 51 51 46 51 51 51 51]\n",
      "Epoch: 8, loss: 5001.162, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 9, loss: 2368.286, training accuracy: 0.00%\n",
      "[75 75 75 75 75 75 75 75 75 75]\n",
      "Epoch: 10, loss: 520490.344, training accuracy: 0.00%\n",
      "[81 81 81 81 81 81 81 81 81 81]\n",
      "Epoch: 11, loss: 5760.351, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 12, loss: 3553.363, training accuracy: 0.00%\n",
      "[98 98 98 98 98 98 98 98 98 98]\n",
      "Epoch: 13, loss: 384.342, training accuracy: 0.00%\n",
      "[32 32 32 32 32 32 32 32 32 32]\n",
      "Epoch: 14, loss: 302.574, training accuracy: 0.00%\n",
      "[37 37 37 37 37 87 37 37 37 37]\n",
      "Epoch: 15, loss: 7231.598, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 16, loss: 6.199, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 17, loss: 4.573, training accuracy: 10.00%\n",
      "[71 68 71 71 71 71 71 71 71 71]\n",
      "Epoch: 18, loss: 41.806, training accuracy: 0.00%\n",
      "[3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch: 19, loss: 752.312, training accuracy: 0.00%\n",
      "[3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch: 20, loss: 25.398, training accuracy: 0.00%\n",
      "[68 68 44 68 68 68 68 68 68 68]\n",
      "Epoch: 21, loss: 4.729, training accuracy: 10.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 22, loss: 4.671, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 23, loss: 4.636, training accuracy: 0.00%\n",
      "[ 17 102  17  17 102  17  17 102  17  17]\n",
      "Epoch: 24, loss: 45318.898, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 25, loss: 3536.960, training accuracy: 10.00%\n",
      "[81 81 81 81 81 81 81 81 81 81]\n",
      "Epoch: 26, loss: 913.038, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 27, loss: 4.593, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 28, loss: 4.847, training accuracy: 10.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 29, loss: 4.830, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 30, loss: 4.451, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 31, loss: 4.651, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 32, loss: 4.956, training accuracy: 0.00%\n",
      "[ 68  68  68  68  68 102  68 102  68  68]\n",
      "Epoch: 33, loss: 4.662, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 34, loss: 16.852, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 35, loss: 4.647, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 36, loss: 4.644, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 37, loss: 5.102, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 38, loss: 4.686, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 39, loss: 4.644, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 40, loss: 4.763, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 41, loss: 5.018, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 42, loss: 4.661, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 43, loss: 4.720, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 44, loss: 4.724, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 45, loss: 4.637, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 46, loss: 4.856, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 47, loss: 4.847, training accuracy: 10.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 48, loss: 4.564, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 49, loss: 4.676, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 50, loss: 4.554, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 51, loss: 4.826, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 52, loss: 4.544, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 53, loss: 4.708, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 54, loss: 4.555, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 55, loss: 4.464, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 56, loss: 4.858, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 57, loss: 4.737, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 58, loss: 4.687, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 59, loss: 4.771, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 60, loss: 4.541, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 61, loss: 4.863, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 62, loss: 4.413, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 63, loss: 4.828, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 64, loss: 4.800, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 65, loss: 4.606, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 66, loss: 4.449, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 67, loss: 4.527, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 68, loss: 4.649, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 69, loss: 4.934, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 70, loss: 4.673, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 71, loss: 4.542, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 72, loss: 4.691, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 73, loss: 4.787, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 74, loss: 4.752, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 75, loss: 4.646, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 76, loss: 4.895, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 77, loss: 4.696, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 78, loss: 4.546, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 79, loss: 4.755, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 80, loss: 4.755, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 81, loss: 4.966, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 82, loss: 4.868, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 83, loss: 4.746, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 84, loss: 4.881, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 85, loss: 4.588, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 86, loss: 4.615, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 87, loss: 4.478, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 88, loss: 4.820, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 89, loss: 4.785, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 90, loss: 4.520, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 91, loss: 4.456, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 92, loss: 4.711, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 93, loss: 4.689, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 94, loss: 4.521, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 95, loss: 4.816, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 96, loss: 4.826, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 97, loss: 4.729, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 98, loss: 4.490, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 99, loss: 4.494, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 100, loss: 4.588, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 101, loss: 4.743, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102, loss: 4.734, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 103, loss: 4.771, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 104, loss: 4.509, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 105, loss: 4.940, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 106, loss: 4.760, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 107, loss: 4.669, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 108, loss: 4.743, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 109, loss: 4.688, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 110, loss: 4.740, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 111, loss: 4.640, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 112, loss: 4.911, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 113, loss: 4.651, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 114, loss: 4.688, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 115, loss: 4.816, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 116, loss: 4.679, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 117, loss: 4.558, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 118, loss: 4.755, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 119, loss: 4.732, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 120, loss: 4.523, training accuracy: 10.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 121, loss: 4.728, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 122, loss: 4.659, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 123, loss: 4.609, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 124, loss: 4.649, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 125, loss: 4.639, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 126, loss: 4.698, training accuracy: 10.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 127, loss: 4.747, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 128, loss: 4.744, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 129, loss: 4.635, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 130, loss: 4.775, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 131, loss: 4.590, training accuracy: 10.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 132, loss: 4.851, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 133, loss: 4.646, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 134, loss: 4.658, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 135, loss: 4.620, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 136, loss: 4.462, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 137, loss: 4.499, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 138, loss: 4.673, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 139, loss: 4.740, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 140, loss: 4.656, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 141, loss: 4.761, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 142, loss: 4.654, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 143, loss: 4.858, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 144, loss: 4.530, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 145, loss: 4.759, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 146, loss: 4.652, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 147, loss: 4.715, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 148, loss: 4.886, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 149, loss: 4.541, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 150, loss: 4.589, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 151, loss: 4.499, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 152, loss: 4.659, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 153, loss: 4.524, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 154, loss: 4.808, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 155, loss: 4.632, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 156, loss: 4.620, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 157, loss: 4.672, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 158, loss: 4.623, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 159, loss: 4.735, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 160, loss: 4.670, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 161, loss: 4.432, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 162, loss: 4.596, training accuracy: 10.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 163, loss: 4.766, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 164, loss: 4.622, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 165, loss: 4.717, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 166, loss: 4.541, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 167, loss: 4.756, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 168, loss: 4.661, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 169, loss: 4.865, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 170, loss: 4.668, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 171, loss: 4.686, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 172, loss: 4.624, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 173, loss: 4.760, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 174, loss: 4.632, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 175, loss: 4.489, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 176, loss: 4.690, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 177, loss: 4.619, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 178, loss: 4.760, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 179, loss: 4.647, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 180, loss: 4.662, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 181, loss: 4.746, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 182, loss: 4.630, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 183, loss: 4.685, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 184, loss: 4.541, training accuracy: 0.00%\n",
      "[99 99 99 99 99 99 99 99 99 99]\n",
      "Epoch: 185, loss: 4.711, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 186, loss: 4.422, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 187, loss: 4.739, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 188, loss: 4.721, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 189, loss: 4.641, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 190, loss: 4.693, training accuracy: 10.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 191, loss: 4.807, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 192, loss: 4.762, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 193, loss: 4.783, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 194, loss: 4.696, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 195, loss: 4.552, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 196, loss: 4.895, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 197, loss: 4.716, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 198, loss: 4.545, training accuracy: 10.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 199, loss: 4.632, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 200, loss: 4.687, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 201, loss: 4.531, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202, loss: 4.573, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 203, loss: 4.708, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 204, loss: 4.767, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 205, loss: 4.695, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 206, loss: 4.751, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 207, loss: 4.602, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 208, loss: 4.770, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 209, loss: 4.555, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 210, loss: 4.473, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 211, loss: 4.648, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 212, loss: 4.785, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 213, loss: 4.626, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 214, loss: 4.779, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 215, loss: 4.563, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 216, loss: 4.680, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 217, loss: 4.735, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 218, loss: 4.645, training accuracy: 10.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 219, loss: 4.515, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 220, loss: 4.586, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 221, loss: 4.626, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 222, loss: 4.753, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 223, loss: 4.685, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 224, loss: 4.562, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 225, loss: 4.595, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 226, loss: 4.403, training accuracy: 10.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 227, loss: 4.704, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 228, loss: 4.697, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 229, loss: 4.550, training accuracy: 10.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 230, loss: 4.795, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 231, loss: 4.727, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 232, loss: 4.733, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 233, loss: 4.562, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 234, loss: 4.669, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 235, loss: 4.527, training accuracy: 10.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 236, loss: 4.747, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 237, loss: 4.717, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 238, loss: 4.706, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 239, loss: 4.837, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 240, loss: 4.569, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 241, loss: 4.633, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 242, loss: 4.602, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 243, loss: 4.847, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 244, loss: 4.601, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 245, loss: 4.594, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 246, loss: 4.687, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 247, loss: 4.685, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 248, loss: 4.978, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 249, loss: 4.687, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 250, loss: 4.552, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 251, loss: 4.775, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 252, loss: 4.633, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 253, loss: 4.566, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 254, loss: 4.637, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 255, loss: 4.741, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 256, loss: 4.593, training accuracy: 10.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 257, loss: 4.527, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 258, loss: 4.650, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 259, loss: 4.752, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 260, loss: 4.916, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 261, loss: 4.670, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 262, loss: 4.600, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 263, loss: 4.592, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 264, loss: 4.444, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 265, loss: 4.787, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 266, loss: 4.580, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 267, loss: 4.706, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 268, loss: 4.688, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 269, loss: 4.693, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 270, loss: 4.702, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 271, loss: 4.720, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 272, loss: 4.592, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 273, loss: 4.661, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 274, loss: 4.634, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 275, loss: 4.693, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 276, loss: 4.597, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 277, loss: 4.741, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 278, loss: 4.658, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 279, loss: 4.612, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 280, loss: 4.727, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 281, loss: 4.737, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 282, loss: 4.652, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 283, loss: 4.557, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 284, loss: 4.581, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 285, loss: 4.673, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 286, loss: 4.738, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 287, loss: 4.783, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 288, loss: 4.601, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 289, loss: 4.698, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 290, loss: 4.527, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 291, loss: 4.564, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 292, loss: 4.668, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 293, loss: 4.792, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 294, loss: 4.553, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 295, loss: 4.729, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 296, loss: 4.532, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 297, loss: 4.685, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 298, loss: 4.666, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 299, loss: 4.566, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 300, loss: 4.783, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 301, loss: 4.636, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 302, loss: 4.683, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 303, loss: 4.738, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 304, loss: 4.489, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 305, loss: 4.603, training accuracy: 10.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 306, loss: 4.791, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 307, loss: 4.619, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 308, loss: 4.578, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 309, loss: 4.683, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 310, loss: 4.666, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 311, loss: 4.636, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 312, loss: 4.808, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 313, loss: 4.773, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 314, loss: 4.594, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 315, loss: 4.701, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 316, loss: 4.683, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 317, loss: 4.692, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 318, loss: 4.677, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 319, loss: 4.765, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 320, loss: 4.654, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 321, loss: 4.644, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 322, loss: 4.661, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 323, loss: 4.756, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 324, loss: 4.875, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 325, loss: 4.716, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 326, loss: 4.671, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 327, loss: 4.555, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 328, loss: 4.590, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 329, loss: 4.609, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 330, loss: 4.558, training accuracy: 10.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 331, loss: 4.697, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 332, loss: 4.727, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 333, loss: 4.771, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 334, loss: 4.812, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 335, loss: 4.418, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 336, loss: 4.673, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 337, loss: 4.770, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 338, loss: 4.723, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 339, loss: 4.628, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 340, loss: 4.713, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 341, loss: 4.702, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 342, loss: 4.788, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 343, loss: 4.797, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 344, loss: 4.576, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 345, loss: 4.662, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 346, loss: 4.674, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 347, loss: 4.633, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 348, loss: 4.584, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 349, loss: 4.691, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 350, loss: 4.741, training accuracy: 10.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 351, loss: 4.696, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 352, loss: 4.650, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 353, loss: 4.656, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 354, loss: 4.822, training accuracy: 0.00%\n",
      "[90 90 90 90 90 90 90 90 90 90]\n",
      "Epoch: 355, loss: 4.699, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 356, loss: 4.741, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 357, loss: 4.741, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 358, loss: 4.663, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 359, loss: 4.555, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 360, loss: 4.637, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 361, loss: 4.683, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 362, loss: 4.645, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 363, loss: 4.673, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 364, loss: 4.637, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 365, loss: 4.663, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 366, loss: 4.820, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 367, loss: 4.605, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 368, loss: 4.696, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 369, loss: 4.663, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 370, loss: 4.733, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 371, loss: 4.628, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 372, loss: 4.597, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 373, loss: 4.623, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 374, loss: 4.605, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 375, loss: 4.566, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 376, loss: 4.767, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 377, loss: 4.662, training accuracy: 10.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 378, loss: 4.677, training accuracy: 10.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 379, loss: 4.668, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 380, loss: 4.712, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 381, loss: 4.709, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 382, loss: 4.707, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 383, loss: 4.552, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 384, loss: 4.652, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 385, loss: 4.710, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 386, loss: 4.793, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 387, loss: 4.625, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 388, loss: 4.705, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 389, loss: 4.664, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 390, loss: 4.693, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 391, loss: 4.670, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 392, loss: 4.838, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 393, loss: 4.580, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 394, loss: 4.680, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 395, loss: 4.533, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 396, loss: 4.823, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 397, loss: 4.754, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 398, loss: 4.702, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 399, loss: 4.729, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 400, loss: 4.572, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 401, loss: 4.548, training accuracy: 0.00%\n",
      "[41 41 41 41 41 41 41 41 41 41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 402, loss: 4.672, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 403, loss: 4.555, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 404, loss: 4.762, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 405, loss: 4.560, training accuracy: 10.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 406, loss: 4.648, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 407, loss: 4.668, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 408, loss: 4.757, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 409, loss: 4.725, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 410, loss: 4.641, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 411, loss: 4.581, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 412, loss: 4.525, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 413, loss: 4.683, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 414, loss: 4.712, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 415, loss: 4.711, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 416, loss: 4.792, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 417, loss: 4.498, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 418, loss: 4.725, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 419, loss: 4.549, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 420, loss: 4.734, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 421, loss: 4.733, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 422, loss: 4.837, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 423, loss: 4.679, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 424, loss: 4.686, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 425, loss: 4.599, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 426, loss: 4.868, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 427, loss: 4.699, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 428, loss: 4.793, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 429, loss: 4.536, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 430, loss: 4.775, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 431, loss: 4.666, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 432, loss: 4.642, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 433, loss: 4.547, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 434, loss: 4.702, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 435, loss: 4.579, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 436, loss: 4.628, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 437, loss: 4.696, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 438, loss: 4.590, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 439, loss: 4.568, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 440, loss: 4.650, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 441, loss: 4.675, training accuracy: 10.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 442, loss: 4.657, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 443, loss: 4.684, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 444, loss: 4.647, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 445, loss: 4.676, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 446, loss: 4.754, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 447, loss: 4.844, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 448, loss: 4.652, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 449, loss: 4.652, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 450, loss: 4.703, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 451, loss: 4.718, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 452, loss: 4.859, training accuracy: 0.00%\n",
      "[23 23 23 23 23 23 23 23 23 23]\n",
      "Epoch: 453, loss: 4.665, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 454, loss: 4.686, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 455, loss: 4.593, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 456, loss: 4.667, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 457, loss: 4.708, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 458, loss: 4.757, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 459, loss: 4.757, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 460, loss: 4.793, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 461, loss: 4.773, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 462, loss: 4.626, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 463, loss: 4.642, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 464, loss: 4.576, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 465, loss: 4.705, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 466, loss: 4.625, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 467, loss: 4.602, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 468, loss: 4.719, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 469, loss: 4.609, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 470, loss: 4.627, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 471, loss: 4.555, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 472, loss: 4.542, training accuracy: 10.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 473, loss: 4.528, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 474, loss: 4.820, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 475, loss: 4.639, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 476, loss: 4.705, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 477, loss: 4.569, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 478, loss: 4.732, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 479, loss: 4.665, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 480, loss: 4.541, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 481, loss: 4.593, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 482, loss: 4.751, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 483, loss: 4.903, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 484, loss: 4.826, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 485, loss: 4.580, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 486, loss: 4.588, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 487, loss: 4.592, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 488, loss: 4.891, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 489, loss: 4.655, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 490, loss: 4.765, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 491, loss: 4.716, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 492, loss: 4.629, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 493, loss: 4.641, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 494, loss: 4.731, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 495, loss: 4.543, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 496, loss: 4.625, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 497, loss: 4.655, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 498, loss: 4.617, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 499, loss: 4.566, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 500, loss: 4.684, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 501, loss: 4.556, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 502, loss: 4.718, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 503, loss: 4.710, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 504, loss: 4.700, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 505, loss: 4.568, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 506, loss: 4.653, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 507, loss: 4.637, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 508, loss: 4.618, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 509, loss: 4.733, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 510, loss: 4.666, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 511, loss: 4.488, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 512, loss: 4.719, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 513, loss: 4.511, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 514, loss: 4.736, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 515, loss: 4.684, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 516, loss: 4.789, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 517, loss: 4.555, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 518, loss: 4.613, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 519, loss: 4.650, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 520, loss: 4.601, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 521, loss: 4.700, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 522, loss: 4.752, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 523, loss: 4.675, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 524, loss: 4.771, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 525, loss: 4.778, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 526, loss: 4.791, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 527, loss: 4.630, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 528, loss: 4.662, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 529, loss: 4.762, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 530, loss: 4.686, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 531, loss: 4.620, training accuracy: 10.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 532, loss: 4.784, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 533, loss: 4.717, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 534, loss: 4.504, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 535, loss: 4.597, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 536, loss: 4.686, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 537, loss: 4.908, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 538, loss: 4.633, training accuracy: 10.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 539, loss: 4.614, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 540, loss: 4.531, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 541, loss: 4.587, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 542, loss: 4.651, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 543, loss: 4.674, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 544, loss: 4.624, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 545, loss: 4.700, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 546, loss: 4.592, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 547, loss: 4.724, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 548, loss: 4.579, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 549, loss: 4.748, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 550, loss: 4.743, training accuracy: 10.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 551, loss: 4.663, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 552, loss: 4.511, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 553, loss: 4.791, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 554, loss: 4.643, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 555, loss: 4.798, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 556, loss: 4.588, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 557, loss: 4.764, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 558, loss: 4.832, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 559, loss: 4.647, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 560, loss: 4.603, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 561, loss: 4.552, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 562, loss: 4.678, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 563, loss: 4.790, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 564, loss: 4.641, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 565, loss: 4.815, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 566, loss: 4.617, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 567, loss: 4.916, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 568, loss: 4.863, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 569, loss: 4.653, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 570, loss: 4.806, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 571, loss: 4.529, training accuracy: 10.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 572, loss: 4.598, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 573, loss: 4.682, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 574, loss: 4.662, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 575, loss: 4.663, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 576, loss: 4.564, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 577, loss: 4.737, training accuracy: 10.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 578, loss: 4.645, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 579, loss: 4.685, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 580, loss: 4.434, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 581, loss: 4.563, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 582, loss: 4.714, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 583, loss: 4.736, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 584, loss: 4.688, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 585, loss: 4.778, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 586, loss: 4.702, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 587, loss: 4.623, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 588, loss: 4.506, training accuracy: 10.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 589, loss: 4.409, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 590, loss: 4.835, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 591, loss: 4.694, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 592, loss: 4.735, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 593, loss: 4.636, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 594, loss: 4.484, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 595, loss: 4.612, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 596, loss: 4.752, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 597, loss: 4.581, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 598, loss: 4.764, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 599, loss: 4.726, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 600, loss: 4.776, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 601, loss: 4.720, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 602, loss: 4.662, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 603, loss: 4.805, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 604, loss: 4.662, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 605, loss: 4.510, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 606, loss: 4.716, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 607, loss: 4.767, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 608, loss: 4.842, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 609, loss: 4.719, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 610, loss: 4.629, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 611, loss: 4.797, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 612, loss: 4.604, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 613, loss: 4.849, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 614, loss: 4.437, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 615, loss: 4.830, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 616, loss: 4.728, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 617, loss: 4.665, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 618, loss: 4.741, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 619, loss: 4.609, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 620, loss: 4.681, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 621, loss: 4.730, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 622, loss: 4.716, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 623, loss: 4.506, training accuracy: 10.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 624, loss: 4.507, training accuracy: 10.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 625, loss: 4.616, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 626, loss: 4.764, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 627, loss: 4.582, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 628, loss: 4.817, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 629, loss: 4.573, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 630, loss: 4.571, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 631, loss: 4.789, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 632, loss: 4.586, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 633, loss: 4.484, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 634, loss: 4.554, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 635, loss: 4.687, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 636, loss: 4.702, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 637, loss: 4.621, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 638, loss: 4.542, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 639, loss: 4.592, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 640, loss: 4.524, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 641, loss: 4.622, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 642, loss: 4.669, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 643, loss: 4.800, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 644, loss: 4.727, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 645, loss: 4.544, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 646, loss: 4.792, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 647, loss: 4.656, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 648, loss: 4.908, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 649, loss: 4.703, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 650, loss: 4.735, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 651, loss: 4.548, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 652, loss: 4.678, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 653, loss: 4.702, training accuracy: 10.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 654, loss: 4.741, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 655, loss: 4.622, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 656, loss: 4.705, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 657, loss: 4.661, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 658, loss: 4.565, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 659, loss: 4.716, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 660, loss: 4.656, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 661, loss: 4.897, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 662, loss: 4.888, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 663, loss: 4.701, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 664, loss: 4.672, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 665, loss: 4.609, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 666, loss: 4.665, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 667, loss: 4.748, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 668, loss: 4.567, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 669, loss: 4.560, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 670, loss: 4.596, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 671, loss: 4.787, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 672, loss: 4.865, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 673, loss: 4.488, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 674, loss: 4.712, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 675, loss: 4.593, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 676, loss: 4.787, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 677, loss: 4.718, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 678, loss: 4.616, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 679, loss: 4.774, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 680, loss: 4.744, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 681, loss: 4.728, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 682, loss: 4.396, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 683, loss: 4.584, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 684, loss: 4.647, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 685, loss: 4.697, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 686, loss: 4.689, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 687, loss: 4.764, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 688, loss: 4.553, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 689, loss: 4.569, training accuracy: 10.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 690, loss: 4.787, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 691, loss: 4.557, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 692, loss: 4.672, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 693, loss: 4.553, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 694, loss: 4.797, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 695, loss: 4.713, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 696, loss: 4.469, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 697, loss: 4.725, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 698, loss: 4.737, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 699, loss: 4.623, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 700, loss: 4.715, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 701, loss: 4.630, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 702, loss: 4.776, training accuracy: 0.00%\n",
      "[61 61 61 61 61 61 61 61 61 61]\n",
      "Epoch: 703, loss: 4.680, training accuracy: 0.00%\n",
      "[17 17 17 17 17 17 17 17 17 17]\n",
      "Epoch: 704, loss: 4.652, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 705, loss: 4.584, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 706, loss: 4.701, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 707, loss: 4.561, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 708, loss: 4.642, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 709, loss: 4.804, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 710, loss: 4.897, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 711, loss: 4.767, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 712, loss: 4.459, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 713, loss: 4.730, training accuracy: 10.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 714, loss: 4.715, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 715, loss: 4.505, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 716, loss: 4.525, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 717, loss: 4.571, training accuracy: 10.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 718, loss: 4.640, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 719, loss: 4.716, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 720, loss: 4.711, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 721, loss: 4.544, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 722, loss: 4.827, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 723, loss: 4.583, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 724, loss: 4.686, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 725, loss: 4.637, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 726, loss: 4.794, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 727, loss: 4.662, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 728, loss: 4.584, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 729, loss: 4.657, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 730, loss: 4.807, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 731, loss: 4.428, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 732, loss: 4.747, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 733, loss: 4.619, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 734, loss: 4.581, training accuracy: 10.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 735, loss: 4.776, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 736, loss: 4.651, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 737, loss: 4.643, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 738, loss: 4.751, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 739, loss: 4.689, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 740, loss: 4.579, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 741, loss: 4.699, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 742, loss: 4.676, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 743, loss: 4.526, training accuracy: 10.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 744, loss: 4.752, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 745, loss: 4.743, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 746, loss: 4.692, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 747, loss: 4.678, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 748, loss: 4.587, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 749, loss: 4.766, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 750, loss: 4.799, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 751, loss: 4.565, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 752, loss: 4.597, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 753, loss: 4.661, training accuracy: 0.00%\n",
      "[50 50 50 50 50 50 50 50 50 50]\n",
      "Epoch: 754, loss: 4.746, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 755, loss: 4.628, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 756, loss: 4.747, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 757, loss: 4.713, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 758, loss: 4.579, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 759, loss: 4.601, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 760, loss: 4.731, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 761, loss: 4.768, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 762, loss: 4.681, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 763, loss: 4.958, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 764, loss: 4.684, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 765, loss: 4.542, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 766, loss: 4.740, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 767, loss: 4.744, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 768, loss: 4.731, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 769, loss: 4.703, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 770, loss: 4.523, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 771, loss: 4.713, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 772, loss: 4.692, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 773, loss: 4.741, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 774, loss: 4.739, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 775, loss: 4.642, training accuracy: 10.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 776, loss: 4.618, training accuracy: 10.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 777, loss: 4.694, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 778, loss: 4.686, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 779, loss: 4.511, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 780, loss: 4.572, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 781, loss: 4.707, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 782, loss: 4.857, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 783, loss: 4.632, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 784, loss: 4.707, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 785, loss: 4.659, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 786, loss: 4.626, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 787, loss: 4.535, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 788, loss: 4.627, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 789, loss: 4.693, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 790, loss: 4.621, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 791, loss: 4.672, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 792, loss: 4.714, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 793, loss: 4.723, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 794, loss: 4.591, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 795, loss: 4.776, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 796, loss: 4.569, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 797, loss: 4.769, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 798, loss: 4.472, training accuracy: 10.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 799, loss: 4.812, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 800, loss: 4.660, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 801, loss: 4.550, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 802, loss: 4.678, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 803, loss: 4.751, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 804, loss: 4.629, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 805, loss: 4.612, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 806, loss: 4.676, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 807, loss: 4.611, training accuracy: 0.00%\n",
      "[72 72 72 72 72 72 72 72 72 72]\n",
      "Epoch: 808, loss: 4.618, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 809, loss: 4.726, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 810, loss: 4.476, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 811, loss: 4.669, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 812, loss: 4.519, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 813, loss: 4.579, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 814, loss: 4.621, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 815, loss: 4.752, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 816, loss: 4.679, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 817, loss: 4.662, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 818, loss: 4.669, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 819, loss: 4.559, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 820, loss: 4.583, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 821, loss: 4.495, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 822, loss: 4.900, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 823, loss: 4.743, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 824, loss: 4.627, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 825, loss: 4.723, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 826, loss: 4.862, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 827, loss: 4.697, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 828, loss: 4.380, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 829, loss: 4.705, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 830, loss: 4.703, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 831, loss: 4.649, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 832, loss: 4.644, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 833, loss: 4.669, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 834, loss: 4.746, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 835, loss: 4.578, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 836, loss: 4.808, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 837, loss: 4.711, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 838, loss: 4.729, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 839, loss: 4.786, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 840, loss: 4.677, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 841, loss: 4.740, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 842, loss: 4.780, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 843, loss: 4.715, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 844, loss: 4.796, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 845, loss: 4.561, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 846, loss: 4.853, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 847, loss: 4.640, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 848, loss: 4.518, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 849, loss: 4.667, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 850, loss: 4.629, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 851, loss: 4.512, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 852, loss: 4.739, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 853, loss: 4.700, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 854, loss: 4.624, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 855, loss: 4.697, training accuracy: 0.00%\n",
      "[60 60 60 60 60 60 60 60 60 60]\n",
      "Epoch: 856, loss: 4.770, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 857, loss: 4.781, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 858, loss: 4.832, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 859, loss: 4.772, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 860, loss: 4.546, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 861, loss: 4.714, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 862, loss: 4.602, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 863, loss: 4.679, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 864, loss: 4.615, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 865, loss: 4.737, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 866, loss: 4.582, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 867, loss: 4.559, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 868, loss: 4.587, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 869, loss: 4.667, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 870, loss: 4.625, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 871, loss: 4.644, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 872, loss: 4.700, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 873, loss: 4.533, training accuracy: 10.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 874, loss: 4.617, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 875, loss: 4.640, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 876, loss: 4.852, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 877, loss: 4.696, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 878, loss: 4.701, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 879, loss: 4.622, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 880, loss: 4.556, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 881, loss: 4.582, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 882, loss: 4.734, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 883, loss: 4.664, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 884, loss: 4.560, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 885, loss: 4.701, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 886, loss: 4.629, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 887, loss: 4.748, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 888, loss: 4.796, training accuracy: 0.00%\n",
      "[2 2 2 2 2 2 2 2 2 2]\n",
      "Epoch: 889, loss: 4.923, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 890, loss: 4.552, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 891, loss: 4.652, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 892, loss: 4.717, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 893, loss: 4.726, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 894, loss: 4.623, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 895, loss: 4.776, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 896, loss: 4.770, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 897, loss: 4.494, training accuracy: 10.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 898, loss: 4.588, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 899, loss: 4.783, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 900, loss: 4.702, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 901, loss: 4.600, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 902, loss: 4.632, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 903, loss: 4.692, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 904, loss: 4.581, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 905, loss: 4.577, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 906, loss: 4.636, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 907, loss: 4.603, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 908, loss: 4.637, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 909, loss: 4.768, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 910, loss: 4.619, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 911, loss: 4.525, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 912, loss: 4.645, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 913, loss: 4.824, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 914, loss: 4.808, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 915, loss: 4.641, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 916, loss: 4.758, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 917, loss: 4.756, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 918, loss: 4.773, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 919, loss: 4.684, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 920, loss: 4.605, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 921, loss: 4.621, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 922, loss: 4.697, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 923, loss: 4.733, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 924, loss: 4.660, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 925, loss: 4.679, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 926, loss: 4.703, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 927, loss: 4.791, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 928, loss: 4.702, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 929, loss: 4.599, training accuracy: 0.00%\n",
      "[12 12 12 12 12 12 12 12 12 12]\n",
      "Epoch: 930, loss: 4.824, training accuracy: 0.00%\n",
      "[81 81 81 81 81 81 81 81 81 81]\n",
      "Epoch: 931, loss: 4.795, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 932, loss: 4.705, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 933, loss: 4.663, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 934, loss: 4.673, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 935, loss: 4.506, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 936, loss: 4.731, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 937, loss: 4.565, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 938, loss: 4.667, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 939, loss: 4.572, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 940, loss: 4.644, training accuracy: 0.00%\n",
      "[84 84 84 84 84 84 84 84 84 84]\n",
      "Epoch: 941, loss: 4.588, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 942, loss: 4.593, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 943, loss: 4.738, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 944, loss: 4.617, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 945, loss: 4.599, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 946, loss: 4.520, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 947, loss: 4.777, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 948, loss: 4.594, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 949, loss: 4.688, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 950, loss: 4.747, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 951, loss: 4.432, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 952, loss: 4.563, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 953, loss: 4.579, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 954, loss: 4.690, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 955, loss: 4.759, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 956, loss: 4.713, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 957, loss: 4.688, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 958, loss: 4.749, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 959, loss: 4.689, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 960, loss: 4.470, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 961, loss: 4.619, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 962, loss: 4.693, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 963, loss: 4.540, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 964, loss: 4.777, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 965, loss: 4.500, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 966, loss: 4.757, training accuracy: 10.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 967, loss: 4.600, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 968, loss: 4.646, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 969, loss: 4.717, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 970, loss: 4.993, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 971, loss: 4.760, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 972, loss: 4.683, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 973, loss: 4.581, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 974, loss: 4.648, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 975, loss: 4.735, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 976, loss: 4.740, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 977, loss: 4.688, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 978, loss: 4.734, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 979, loss: 4.561, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 980, loss: 4.691, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 981, loss: 4.599, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 982, loss: 4.722, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 983, loss: 4.654, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 984, loss: 4.610, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 985, loss: 4.749, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 986, loss: 4.911, training accuracy: 0.00%\n",
      "[76 76 76 76 76 76 76 76 76 76]\n",
      "Epoch: 987, loss: 4.533, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 988, loss: 4.674, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 989, loss: 4.605, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 990, loss: 4.714, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 991, loss: 4.486, training accuracy: 10.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 992, loss: 4.643, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 993, loss: 4.685, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 994, loss: 4.603, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 995, loss: 4.755, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 996, loss: 4.615, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 997, loss: 4.691, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 998, loss: 4.774, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 999, loss: 4.628, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1000, loss: 4.688, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1001, loss: 4.656, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1002, loss: 4.699, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1003, loss: 4.690, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1004, loss: 4.641, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1005, loss: 5.066, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1006, loss: 4.610, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1007, loss: 4.647, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1008, loss: 4.657, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1009, loss: 4.753, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1010, loss: 4.810, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1011, loss: 4.673, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1012, loss: 4.544, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1013, loss: 4.652, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1014, loss: 4.670, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1015, loss: 4.755, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1016, loss: 4.741, training accuracy: 0.00%\n",
      "[89 89 89 89 89 89 89 89 89 89]\n",
      "Epoch: 1017, loss: 4.651, training accuracy: 0.00%\n",
      "[89 89 89 89 89 89 89 89 89 89]\n",
      "Epoch: 1018, loss: 4.659, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 1019, loss: 4.733, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 1020, loss: 4.842, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1021, loss: 4.701, training accuracy: 10.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1022, loss: 4.607, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1023, loss: 4.654, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1024, loss: 4.690, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1025, loss: 4.565, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1026, loss: 4.712, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1027, loss: 4.586, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1028, loss: 4.867, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1029, loss: 4.428, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1030, loss: 4.938, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1031, loss: 4.598, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1032, loss: 4.469, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1033, loss: 4.629, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1034, loss: 4.762, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1035, loss: 4.603, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1036, loss: 4.662, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1037, loss: 4.495, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1038, loss: 4.535, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1039, loss: 4.736, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1040, loss: 4.860, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1041, loss: 4.576, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1042, loss: 4.740, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1043, loss: 4.694, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1044, loss: 4.675, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1045, loss: 4.723, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1046, loss: 4.786, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1047, loss: 4.717, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1048, loss: 4.614, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1049, loss: 4.798, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1050, loss: 4.725, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1051, loss: 4.704, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1052, loss: 4.713, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1053, loss: 4.663, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1054, loss: 4.778, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1055, loss: 4.610, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1056, loss: 4.520, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1057, loss: 4.585, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1058, loss: 4.583, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1059, loss: 4.809, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1060, loss: 4.655, training accuracy: 10.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1061, loss: 4.674, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1062, loss: 4.625, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1063, loss: 4.680, training accuracy: 0.00%\n",
      "[7 7 7 7 7 7 7 7 7 7]\n",
      "Epoch: 1064, loss: 4.680, training accuracy: 0.00%\n",
      "[7 7 7 7 7 7 7 7 7 7]\n",
      "Epoch: 1065, loss: 4.659, training accuracy: 0.00%\n",
      "[7 7 7 7 7 7 7 7 7 7]\n",
      "Epoch: 1066, loss: 4.716, training accuracy: 0.00%\n",
      "[7 7 7 7 7 7 7 7 7 7]\n",
      "Epoch: 1067, loss: 4.592, training accuracy: 0.00%\n",
      "[7 7 7 7 7 7 7 7 7 7]\n",
      "Epoch: 1068, loss: 4.688, training accuracy: 0.00%\n",
      "[7 7 7 7 7 7 7 7 7 7]\n",
      "Epoch: 1069, loss: 4.366, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1070, loss: 4.694, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1071, loss: 4.567, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1072, loss: 4.662, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1073, loss: 4.787, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1074, loss: 4.595, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1075, loss: 4.842, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1076, loss: 4.755, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1077, loss: 4.615, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1078, loss: 4.689, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1079, loss: 4.505, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1080, loss: 4.691, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1081, loss: 4.696, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 1082, loss: 4.721, training accuracy: 0.00%\n",
      "[68 68 68 68 68 68 68 68 68 68]\n",
      "Epoch: 1083, loss: 4.811, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1084, loss: 4.727, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1085, loss: 4.766, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1086, loss: 4.839, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1087, loss: 4.788, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1088, loss: 4.600, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1089, loss: 4.568, training accuracy: 0.00%\n",
      "[21 21 21 21 21 21 21 21 21 21]\n",
      "Epoch: 1090, loss: 4.732, training accuracy: 0.00%\n",
      "[21 21 21 21 21 21 21 21 21 21]\n",
      "Epoch: 1091, loss: 4.756, training accuracy: 0.00%\n",
      "[21 21 21 21 21 21 21 21 21 21]\n",
      "Epoch: 1092, loss: 4.818, training accuracy: 0.00%\n",
      "[21 21 21 21 21 21 21 21 21 21]\n",
      "Epoch: 1093, loss: 4.703, training accuracy: 0.00%\n",
      "[21 21 21 21 21 21 21 21 21 21]\n",
      "Epoch: 1094, loss: 4.705, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1095, loss: 4.514, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1096, loss: 4.789, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1097, loss: 4.629, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1098, loss: 4.593, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1099, loss: 4.616, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1100, loss: 4.639, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1101, loss: 4.757, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1102, loss: 4.628, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1103, loss: 4.561, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1104, loss: 4.752, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1105, loss: 4.845, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1106, loss: 4.570, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1107, loss: 4.692, training accuracy: 0.00%\n",
      "[75 75 75 75 75 75 75 75 75 75]\n",
      "Epoch: 1108, loss: 4.622, training accuracy: 0.00%\n",
      "[75 75 75 75 75 75 75 75 75 75]\n",
      "Epoch: 1109, loss: 4.549, training accuracy: 0.00%\n",
      "[75 75 75 75 75 75 75 75 75 75]\n",
      "Epoch: 1110, loss: 4.714, training accuracy: 0.00%\n",
      "[75 75 75 75 75 75 75 75 75 75]\n",
      "Epoch: 1111, loss: 4.658, training accuracy: 0.00%\n",
      "[75 75 75 75 75 75 75 75 75 75]\n",
      "Epoch: 1112, loss: 4.722, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1113, loss: 4.678, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1114, loss: 4.555, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1115, loss: 4.605, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1116, loss: 4.727, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1117, loss: 4.522, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1118, loss: 4.589, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1119, loss: 4.907, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1120, loss: 4.572, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1121, loss: 4.592, training accuracy: 10.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1122, loss: 4.536, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1123, loss: 4.753, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1124, loss: 4.741, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1125, loss: 4.711, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1126, loss: 4.847, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1127, loss: 4.620, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1128, loss: 4.727, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1129, loss: 4.568, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1130, loss: 4.699, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1131, loss: 4.773, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1132, loss: 4.677, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1133, loss: 4.531, training accuracy: 10.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1134, loss: 4.774, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1135, loss: 4.661, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1136, loss: 4.718, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1137, loss: 4.654, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1138, loss: 4.686, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1139, loss: 4.607, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1140, loss: 4.856, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1141, loss: 4.578, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1142, loss: 4.740, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1143, loss: 4.556, training accuracy: 10.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1144, loss: 4.660, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1145, loss: 4.533, training accuracy: 10.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1146, loss: 4.823, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1147, loss: 4.796, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1148, loss: 4.375, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1149, loss: 4.741, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1150, loss: 4.572, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1151, loss: 4.621, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1152, loss: 4.630, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1153, loss: 4.651, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1154, loss: 4.781, training accuracy: 10.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1155, loss: 4.701, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1156, loss: 4.709, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1157, loss: 4.570, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1158, loss: 4.816, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1159, loss: 4.497, training accuracy: 0.00%\n",
      "[62 62 62 62 62 62 62 62 62 62]\n",
      "Epoch: 1160, loss: 4.686, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1161, loss: 4.621, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1162, loss: 4.811, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1163, loss: 4.676, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1164, loss: 4.692, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1165, loss: 4.683, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1166, loss: 4.566, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1167, loss: 4.782, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1168, loss: 4.692, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1169, loss: 4.616, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1170, loss: 4.491, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1171, loss: 4.646, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1172, loss: 4.542, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1173, loss: 4.416, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1174, loss: 4.588, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1175, loss: 4.608, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1176, loss: 4.813, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1177, loss: 4.576, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1178, loss: 4.695, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1179, loss: 4.750, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1180, loss: 4.564, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1181, loss: 4.689, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1182, loss: 4.576, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1183, loss: 4.729, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1184, loss: 4.470, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1185, loss: 4.773, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1186, loss: 4.687, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1187, loss: 4.698, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1188, loss: 4.661, training accuracy: 10.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1189, loss: 4.642, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1190, loss: 4.812, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1191, loss: 4.675, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1192, loss: 4.675, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1193, loss: 4.743, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1194, loss: 4.734, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1195, loss: 4.685, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1196, loss: 4.496, training accuracy: 10.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1197, loss: 4.632, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1198, loss: 4.534, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1199, loss: 4.649, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1200, loss: 4.659, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1201, loss: 4.793, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1202, loss: 4.695, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1203, loss: 4.878, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1204, loss: 4.684, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1205, loss: 4.770, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1206, loss: 4.701, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1207, loss: 4.707, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1208, loss: 4.445, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1209, loss: 4.603, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1210, loss: 4.770, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1211, loss: 4.673, training accuracy: 20.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1212, loss: 4.824, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1213, loss: 4.537, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1214, loss: 4.620, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1215, loss: 4.587, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1216, loss: 4.856, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1217, loss: 4.771, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1218, loss: 4.646, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1219, loss: 4.748, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1220, loss: 4.821, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1221, loss: 4.612, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1222, loss: 4.698, training accuracy: 0.00%\n",
      "[92 92 92 92 92 92 92 92 92 92]\n",
      "Epoch: 1223, loss: 4.728, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1224, loss: 4.650, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1225, loss: 4.570, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1226, loss: 4.590, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1227, loss: 4.896, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1228, loss: 4.652, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1229, loss: 4.922, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1230, loss: 4.497, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1231, loss: 4.715, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1232, loss: 4.883, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1233, loss: 4.685, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1234, loss: 4.847, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1235, loss: 4.627, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1236, loss: 4.796, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1237, loss: 4.706, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1238, loss: 4.713, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1239, loss: 4.575, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1240, loss: 4.590, training accuracy: 0.00%\n",
      "[29 29 29 29 29 29 29 29 29 29]\n",
      "Epoch: 1241, loss: 4.568, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1242, loss: 4.693, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1243, loss: 4.628, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1244, loss: 4.653, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1245, loss: 4.546, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1246, loss: 4.671, training accuracy: 0.00%\n",
      "[98 98 98 98 98 98 98 98 98 98]\n",
      "Epoch: 1247, loss: 4.670, training accuracy: 0.00%\n",
      "[98 98 98 98 98 98 98 98 98 98]\n",
      "Epoch: 1248, loss: 4.895, training accuracy: 0.00%\n",
      "[22 22 22 22 22 22 22 22 22 22]\n",
      "Epoch: 1249, loss: 4.639, training accuracy: 0.00%\n",
      "[22 22 22 22 22 22 22 22 22 22]\n",
      "Epoch: 1250, loss: 4.742, training accuracy: 0.00%\n",
      "[22 22 22 22 22 22 22 22 22 22]\n",
      "Epoch: 1251, loss: 4.705, training accuracy: 0.00%\n",
      "[22 22 22 22 22 22 22 22 22 22]\n",
      "Epoch: 1252, loss: 4.863, training accuracy: 0.00%\n",
      "[22 22 22 22 22 22 22 22 22 22]\n",
      "Epoch: 1253, loss: 4.663, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1254, loss: 4.551, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1255, loss: 4.632, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1256, loss: 4.628, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1257, loss: 4.707, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1258, loss: 4.684, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1259, loss: 4.692, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1260, loss: 4.593, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1261, loss: 4.731, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1262, loss: 4.753, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1263, loss: 4.750, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1264, loss: 4.604, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1265, loss: 4.684, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1266, loss: 4.683, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1267, loss: 4.623, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1268, loss: 4.587, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1269, loss: 4.616, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1270, loss: 4.623, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1271, loss: 4.632, training accuracy: 10.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1272, loss: 4.598, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1273, loss: 4.762, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1274, loss: 4.709, training accuracy: 0.00%\n",
      "[54 54 54 54 54 54 54 54 54 54]\n",
      "Epoch: 1275, loss: 4.675, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1276, loss: 4.857, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1277, loss: 4.547, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1278, loss: 4.673, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1279, loss: 4.473, training accuracy: 10.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1280, loss: 4.819, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1281, loss: 4.655, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1282, loss: 4.860, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1283, loss: 4.719, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1284, loss: 4.662, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1285, loss: 4.689, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1286, loss: 4.597, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1287, loss: 4.622, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1288, loss: 4.781, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1289, loss: 4.702, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1290, loss: 4.866, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1291, loss: 4.743, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1292, loss: 4.616, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1293, loss: 4.586, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1294, loss: 4.717, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1295, loss: 4.539, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1296, loss: 4.783, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1297, loss: 4.897, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1298, loss: 4.727, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1299, loss: 4.773, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1300, loss: 4.625, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1301, loss: 4.703, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1302, loss: 4.477, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1303, loss: 4.751, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1304, loss: 4.635, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1305, loss: 4.724, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1306, loss: 4.493, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1307, loss: 4.586, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1308, loss: 4.655, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1309, loss: 4.519, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 1310, loss: 4.749, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 1311, loss: 4.706, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 1312, loss: 4.591, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 1313, loss: 4.703, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 1314, loss: 4.584, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 1315, loss: 4.603, training accuracy: 0.00%\n",
      "[77 77 77 77 77 77 77 77 77 77]\n",
      "Epoch: 1316, loss: 4.756, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1317, loss: 4.727, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1318, loss: 4.723, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1319, loss: 4.555, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1320, loss: 4.593, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1321, loss: 4.575, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1322, loss: 4.727, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1323, loss: 4.628, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1324, loss: 4.596, training accuracy: 10.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1325, loss: 4.673, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1326, loss: 4.682, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1327, loss: 4.759, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1328, loss: 4.760, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1329, loss: 4.565, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1330, loss: 4.872, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1331, loss: 4.744, training accuracy: 10.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1332, loss: 4.695, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1333, loss: 4.789, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1334, loss: 4.630, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1335, loss: 4.813, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1336, loss: 4.671, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1337, loss: 4.651, training accuracy: 10.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1338, loss: 4.466, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1339, loss: 4.626, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1340, loss: 4.744, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1341, loss: 4.629, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1342, loss: 4.708, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1343, loss: 4.837, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1344, loss: 4.584, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1345, loss: 4.724, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1346, loss: 4.754, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1347, loss: 4.583, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1348, loss: 4.559, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1349, loss: 4.502, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1350, loss: 5.011, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1351, loss: 4.699, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1352, loss: 4.680, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1353, loss: 4.564, training accuracy: 10.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1354, loss: 4.772, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1355, loss: 4.646, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1356, loss: 4.750, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1357, loss: 4.751, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1358, loss: 4.688, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1359, loss: 4.610, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1360, loss: 4.660, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1361, loss: 4.769, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1362, loss: 4.772, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1363, loss: 4.861, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1364, loss: 4.776, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1365, loss: 4.789, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1366, loss: 4.717, training accuracy: 0.00%\n",
      "[93 93 93 93 93 93 93 93 93 93]\n",
      "Epoch: 1367, loss: 4.582, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 1368, loss: 4.615, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 1369, loss: 4.747, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 1370, loss: 4.719, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 1371, loss: 4.645, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 1372, loss: 4.584, training accuracy: 0.00%\n",
      "[31 31 31 31 31 31 31 31 31 31]\n",
      "Epoch: 1373, loss: 4.629, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1374, loss: 4.606, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1375, loss: 4.741, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1376, loss: 4.631, training accuracy: 10.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1377, loss: 4.726, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1378, loss: 4.777, training accuracy: 10.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1379, loss: 4.542, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1380, loss: 4.628, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1381, loss: 4.781, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1382, loss: 4.807, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1383, loss: 4.487, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1384, loss: 4.736, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1385, loss: 4.693, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1386, loss: 4.807, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1387, loss: 4.572, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1388, loss: 4.690, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1389, loss: 4.608, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1390, loss: 4.469, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1391, loss: 4.797, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1392, loss: 4.563, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1393, loss: 4.563, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1394, loss: 4.654, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1395, loss: 4.758, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1396, loss: 4.576, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1397, loss: 4.637, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1398, loss: 4.898, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1399, loss: 4.587, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1400, loss: 4.695, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1401, loss: 4.549, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1402, loss: 4.670, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1403, loss: 4.710, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1404, loss: 4.863, training accuracy: 10.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1405, loss: 4.656, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1406, loss: 4.585, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1407, loss: 4.628, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1408, loss: 4.711, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1409, loss: 4.733, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1410, loss: 4.510, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1411, loss: 4.736, training accuracy: 0.00%\n",
      "[91 91 91 91 91 91 91 91 91 91]\n",
      "Epoch: 1412, loss: 4.719, training accuracy: 0.00%\n",
      "[91 91 91 91 91 91 91 91 91 91]\n",
      "Epoch: 1413, loss: 4.599, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1414, loss: 4.845, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1415, loss: 4.761, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1416, loss: 4.901, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1417, loss: 4.780, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1418, loss: 4.713, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1419, loss: 4.750, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1420, loss: 4.476, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1421, loss: 4.467, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1422, loss: 4.633, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1423, loss: 4.548, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1424, loss: 4.583, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1425, loss: 4.639, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1426, loss: 4.636, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1427, loss: 4.633, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1428, loss: 4.771, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1429, loss: 4.560, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1430, loss: 4.680, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1431, loss: 4.709, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1432, loss: 4.806, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1433, loss: 4.622, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1434, loss: 4.613, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1435, loss: 4.777, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1436, loss: 4.693, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1437, loss: 4.763, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1438, loss: 4.568, training accuracy: 0.00%\n",
      "[40 40 40 40 40 40 40 40 40 40]\n",
      "Epoch: 1439, loss: 4.699, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1440, loss: 4.629, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1441, loss: 4.629, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1442, loss: 4.630, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1443, loss: 4.851, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1444, loss: 4.656, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1445, loss: 4.628, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1446, loss: 4.749, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1447, loss: 4.841, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1448, loss: 4.680, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1449, loss: 4.600, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1450, loss: 4.872, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1451, loss: 4.720, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1452, loss: 4.748, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1453, loss: 4.527, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1454, loss: 4.682, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1455, loss: 4.744, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1456, loss: 4.689, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1457, loss: 4.725, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1458, loss: 4.695, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1459, loss: 4.611, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1460, loss: 4.578, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1461, loss: 4.677, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1462, loss: 4.745, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1463, loss: 4.523, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1464, loss: 4.781, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1465, loss: 4.670, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1466, loss: 4.573, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1467, loss: 4.507, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1468, loss: 4.858, training accuracy: 0.00%\n",
      "[94 94 94 94 94 94 94 94 94 94]\n",
      "Epoch: 1469, loss: 4.645, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1470, loss: 4.584, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1471, loss: 4.778, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1472, loss: 4.656, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1473, loss: 4.519, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1474, loss: 4.780, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1475, loss: 4.512, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1476, loss: 4.745, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1477, loss: 4.534, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1478, loss: 4.720, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1479, loss: 4.476, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1480, loss: 4.639, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1481, loss: 4.742, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1482, loss: 4.865, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1483, loss: 4.576, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1484, loss: 4.639, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1485, loss: 4.819, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1486, loss: 4.616, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1487, loss: 4.622, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1488, loss: 4.582, training accuracy: 0.00%\n",
      "[74 74 74 74 74 74 74 74 74 74]\n",
      "Epoch: 1489, loss: 4.778, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 1490, loss: 4.803, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 1491, loss: 4.743, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 1492, loss: 4.799, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1493, loss: 4.822, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1494, loss: 4.650, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1495, loss: 4.506, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1496, loss: 4.676, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1497, loss: 4.681, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1498, loss: 4.881, training accuracy: 0.00%\n",
      "[42 42 42 42 42 42 42 42 42 42]\n",
      "Epoch: 1499, loss: 4.775, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 1500, loss: 4.679, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 1501, loss: 4.752, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 1502, loss: 4.846, training accuracy: 0.00%\n",
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "Epoch: 1503, loss: 4.583, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1504, loss: 4.716, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1505, loss: 4.620, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1506, loss: 4.829, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1507, loss: 4.614, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1508, loss: 4.554, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1509, loss: 4.759, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1510, loss: 4.789, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1511, loss: 4.697, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1512, loss: 4.568, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1513, loss: 4.476, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1514, loss: 4.955, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1515, loss: 4.448, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1516, loss: 4.614, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1517, loss: 4.611, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1518, loss: 4.705, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1519, loss: 4.657, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1520, loss: 4.599, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1521, loss: 4.621, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1522, loss: 4.610, training accuracy: 10.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1523, loss: 4.482, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1524, loss: 4.491, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1525, loss: 4.754, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1526, loss: 4.818, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1527, loss: 4.827, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1528, loss: 4.655, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1529, loss: 4.695, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1530, loss: 4.734, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1531, loss: 4.615, training accuracy: 10.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1532, loss: 4.810, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1533, loss: 4.646, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1534, loss: 4.743, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1535, loss: 4.564, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1536, loss: 4.885, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1537, loss: 4.612, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1538, loss: 4.576, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1539, loss: 4.615, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1540, loss: 4.465, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1541, loss: 4.669, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1542, loss: 4.563, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1543, loss: 4.835, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1544, loss: 4.745, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1545, loss: 4.659, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1546, loss: 4.591, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1547, loss: 4.766, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1548, loss: 4.607, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1549, loss: 4.640, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1550, loss: 4.529, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1551, loss: 4.623, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1552, loss: 4.648, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1553, loss: 4.865, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1554, loss: 4.585, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1555, loss: 4.703, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1556, loss: 4.571, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1557, loss: 4.566, training accuracy: 0.00%\n",
      "[64 64 64 64 64 64 64 64 64 64]\n",
      "Epoch: 1558, loss: 4.891, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1559, loss: 4.594, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1560, loss: 4.619, training accuracy: 0.00%\n",
      "[70 70 70 70 70 70 70 70 70 70]\n",
      "Epoch: 1561, loss: 4.942, training accuracy: 0.00%\n",
      "[70 70 70 70 70 70 70 70 70 70]\n",
      "Epoch: 1562, loss: 4.725, training accuracy: 0.00%\n",
      "[70 70 70 70 70 70 70 70 70 70]\n",
      "Epoch: 1563, loss: 4.800, training accuracy: 0.00%\n",
      "[70 70 70 70 70 70 70 70 70 70]\n",
      "Epoch: 1564, loss: 4.676, training accuracy: 0.00%\n",
      "[70 70 70 70 70 70 70 70 70 70]\n",
      "Epoch: 1565, loss: 4.743, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1566, loss: 4.591, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1567, loss: 4.672, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1568, loss: 4.687, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1569, loss: 4.737, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1570, loss: 4.610, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1571, loss: 4.682, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1572, loss: 4.687, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1573, loss: 4.582, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1574, loss: 4.820, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1575, loss: 4.568, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1576, loss: 4.525, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n",
      "Epoch: 1577, loss: 4.711, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1578, loss: 4.563, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1579, loss: 4.714, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1580, loss: 4.827, training accuracy: 0.00%\n",
      "[36 36 36 36 36 36 36 36 36 36]\n",
      "Epoch: 1581, loss: 4.593, training accuracy: 0.00%\n",
      "[36 36 36 36 36 36 36 36 36 36]\n",
      "Epoch: 1582, loss: 4.536, training accuracy: 0.00%\n",
      "[36 36 36 36 36 36 36 36 36 36]\n",
      "Epoch: 1583, loss: 4.753, training accuracy: 0.00%\n",
      "[36 36 36 36 36 36 36 36 36 36]\n",
      "Epoch: 1584, loss: 4.657, training accuracy: 0.00%\n",
      "[36 36 36 36 36 36 36 36 36 36]\n",
      "Epoch: 1585, loss: 4.729, training accuracy: 0.00%\n",
      "[36 36 36 36 36 36 36 36 36 36]\n",
      "Epoch: 1586, loss: 4.651, training accuracy: 0.00%\n",
      "[36 36 36 36 36 36 36 36 36 36]\n",
      "Epoch: 1587, loss: 4.516, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1588, loss: 4.776, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1589, loss: 4.664, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1590, loss: 4.317, training accuracy: 20.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1591, loss: 4.669, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1592, loss: 4.685, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1593, loss: 4.694, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1594, loss: 4.752, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1595, loss: 4.538, training accuracy: 0.00%\n",
      "[43 43 43 43 43 43 43 43 43 43]\n",
      "Epoch: 1596, loss: 4.649, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1597, loss: 4.724, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1598, loss: 4.619, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1599, loss: 4.747, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1600, loss: 4.760, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1601, loss: 4.635, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1602, loss: 4.705, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1603, loss: 4.660, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1604, loss: 4.544, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1605, loss: 4.781, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1606, loss: 4.686, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1607, loss: 4.761, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1608, loss: 4.644, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1609, loss: 4.729, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1610, loss: 4.604, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1611, loss: 4.555, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1612, loss: 4.606, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1613, loss: 4.502, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1614, loss: 4.879, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1615, loss: 4.673, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1616, loss: 4.563, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1617, loss: 4.684, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1618, loss: 4.793, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1619, loss: 4.729, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1620, loss: 4.602, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1621, loss: 4.641, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1622, loss: 4.571, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1623, loss: 4.662, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1624, loss: 4.768, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1625, loss: 4.730, training accuracy: 0.00%\n",
      "[86 86 86 86 86 86 86 86 86 86]\n",
      "Epoch: 1626, loss: 4.776, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1627, loss: 4.778, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1628, loss: 4.494, training accuracy: 10.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1629, loss: 4.664, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1630, loss: 4.608, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1631, loss: 4.593, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1632, loss: 4.754, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1633, loss: 4.564, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1634, loss: 4.755, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1635, loss: 4.687, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1636, loss: 4.654, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1637, loss: 4.688, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1638, loss: 4.743, training accuracy: 10.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1639, loss: 4.617, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1640, loss: 4.535, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1641, loss: 4.704, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1642, loss: 4.600, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1643, loss: 4.762, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1644, loss: 4.703, training accuracy: 0.00%\n",
      "[87 87 87 87 87 87 87 87 87 87]\n",
      "Epoch: 1645, loss: 4.789, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1646, loss: 4.730, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1647, loss: 4.866, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1648, loss: 4.497, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1649, loss: 4.541, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1650, loss: 4.766, training accuracy: 10.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1651, loss: 4.596, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1652, loss: 4.637, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1653, loss: 4.505, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1654, loss: 4.495, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1655, loss: 4.593, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1656, loss: 4.729, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1657, loss: 4.549, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1658, loss: 4.664, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1659, loss: 4.648, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1660, loss: 4.661, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1661, loss: 4.860, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1662, loss: 4.691, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1663, loss: 4.612, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1664, loss: 4.576, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1665, loss: 4.880, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1666, loss: 4.824, training accuracy: 10.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1667, loss: 4.845, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1668, loss: 4.857, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1669, loss: 4.694, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1670, loss: 4.738, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1671, loss: 4.568, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1672, loss: 4.591, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1673, loss: 4.727, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1674, loss: 4.725, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1675, loss: 4.595, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1676, loss: 4.618, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1677, loss: 4.662, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1678, loss: 4.568, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1679, loss: 4.512, training accuracy: 10.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1680, loss: 4.649, training accuracy: 0.00%\n",
      "[46 46 46 46 46 46 46 46 46 46]\n",
      "Epoch: 1681, loss: 4.716, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1682, loss: 4.822, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1683, loss: 4.761, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1684, loss: 4.726, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1685, loss: 4.701, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1686, loss: 4.492, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1687, loss: 4.813, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1688, loss: 4.688, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1689, loss: 4.787, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1690, loss: 4.717, training accuracy: 0.00%\n",
      "[6 6 6 6 6 6 6 6 6 6]\n",
      "Epoch: 1691, loss: 4.687, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 1692, loss: 4.809, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 1693, loss: 4.549, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 1694, loss: 4.527, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 1695, loss: 4.592, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 1696, loss: 4.720, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 1697, loss: 4.519, training accuracy: 0.00%\n",
      "[14 14 14 14 14 14 14 14 14 14]\n",
      "Epoch: 1698, loss: 4.771, training accuracy: 0.00%\n",
      "[15 15 15 15 15 15 15 15 15 15]\n",
      "Epoch: 1699, loss: 4.663, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1700, loss: 4.794, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1701, loss: 4.708, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1702, loss: 4.752, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1703, loss: 4.879, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1704, loss: 4.645, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1705, loss: 4.721, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1706, loss: 4.829, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1707, loss: 4.684, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1708, loss: 4.660, training accuracy: 10.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1709, loss: 4.765, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1710, loss: 4.659, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1711, loss: 4.675, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1712, loss: 4.747, training accuracy: 10.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1713, loss: 4.639, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1714, loss: 4.529, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1715, loss: 4.558, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1716, loss: 4.719, training accuracy: 0.00%\n",
      "[78 78 78 78 78 78 78 78 78 78]\n",
      "Epoch: 1717, loss: 4.877, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1718, loss: 4.709, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1719, loss: 4.560, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1720, loss: 4.602, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1721, loss: 4.881, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1722, loss: 4.647, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1723, loss: 4.800, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1724, loss: 4.742, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1725, loss: 4.755, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1726, loss: 4.734, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1727, loss: 4.524, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1728, loss: 4.649, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1729, loss: 4.712, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1730, loss: 4.707, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1731, loss: 4.570, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1732, loss: 4.643, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1733, loss: 4.628, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1734, loss: 4.818, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1735, loss: 4.653, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1736, loss: 4.663, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1737, loss: 4.647, training accuracy: 0.00%\n",
      "[47 47 47 47 47 47 47 47 47 47]\n",
      "Epoch: 1738, loss: 4.653, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1739, loss: 4.564, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1740, loss: 4.719, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1741, loss: 4.739, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1742, loss: 4.640, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1743, loss: 4.752, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1744, loss: 4.654, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1745, loss: 4.572, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1746, loss: 4.558, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1747, loss: 4.663, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1748, loss: 4.672, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1749, loss: 4.607, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1750, loss: 4.505, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1751, loss: 4.633, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1752, loss: 4.642, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 1753, loss: 4.780, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 1754, loss: 4.616, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 1755, loss: 4.871, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 1756, loss: 4.538, training accuracy: 0.00%\n",
      "[97 97 97 97 97 97 97 97 97 97]\n",
      "Epoch: 1757, loss: 4.846, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1758, loss: 4.718, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1759, loss: 4.501, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1760, loss: 4.666, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1761, loss: 4.628, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1762, loss: 4.690, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1763, loss: 4.645, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1764, loss: 4.633, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1765, loss: 4.717, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1766, loss: 4.647, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1767, loss: 4.931, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1768, loss: 4.754, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1769, loss: 4.843, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1770, loss: 4.730, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1771, loss: 4.664, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1772, loss: 4.679, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1773, loss: 4.584, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1774, loss: 4.692, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1775, loss: 4.724, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1776, loss: 4.591, training accuracy: 10.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1777, loss: 4.553, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1778, loss: 4.766, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1779, loss: 4.597, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1780, loss: 4.591, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1781, loss: 4.654, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1782, loss: 4.590, training accuracy: 0.00%\n",
      "[55 55 55 55 55 55 55 55 55 55]\n",
      "Epoch: 1783, loss: 4.738, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1784, loss: 4.735, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1785, loss: 4.598, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1786, loss: 4.720, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1787, loss: 4.607, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1788, loss: 4.553, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1789, loss: 4.735, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1790, loss: 4.661, training accuracy: 0.00%\n",
      "[59 59 59 59 59 59 59 59 59 59]\n",
      "Epoch: 1791, loss: 4.627, training accuracy: 0.00%\n",
      "[30 30 30 30 30 30 30 30 30 30]\n",
      "Epoch: 1792, loss: 4.596, training accuracy: 0.00%\n",
      "[30 30 30 30 30 30 30 30 30 30]\n",
      "Epoch: 1793, loss: 4.630, training accuracy: 10.00%\n",
      "[30 30 30 30 30 30 30 30 30 30]\n",
      "Epoch: 1794, loss: 4.590, training accuracy: 0.00%\n",
      "[30 30 30 30 30 30 30 30 30 30]\n",
      "Epoch: 1795, loss: 4.589, training accuracy: 0.00%\n",
      "[18 18 18 18 18 18 18 18 18 18]\n",
      "Epoch: 1796, loss: 4.600, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1797, loss: 4.627, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1798, loss: 4.615, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1799, loss: 4.606, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1800, loss: 4.627, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1801, loss: 4.730, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1802, loss: 4.660, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1803, loss: 4.729, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1804, loss: 4.552, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1805, loss: 4.666, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1806, loss: 4.794, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1807, loss: 4.894, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1808, loss: 4.734, training accuracy: 10.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1809, loss: 4.670, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1810, loss: 4.682, training accuracy: 0.00%\n",
      "[98 98 98 98 98 98 98 98 98 98]\n",
      "Epoch: 1811, loss: 4.588, training accuracy: 0.00%\n",
      "[98 98 98 98 98 98 98 98 98 98]\n",
      "Epoch: 1812, loss: 4.673, training accuracy: 0.00%\n",
      "[98 98 98 98 98 98 98 98 98 98]\n",
      "Epoch: 1813, loss: 4.568, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1814, loss: 4.529, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1815, loss: 4.539, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1816, loss: 4.754, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1817, loss: 4.607, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1818, loss: 4.713, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1819, loss: 4.905, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1820, loss: 4.595, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1821, loss: 4.624, training accuracy: 0.00%\n",
      "[66 66 66 66 66 66 66 66 66 66]\n",
      "Epoch: 1822, loss: 4.774, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 1823, loss: 4.687, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 1824, loss: 4.667, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 1825, loss: 4.670, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 1826, loss: 4.579, training accuracy: 0.00%\n",
      "[73 73 73 73 73 73 73 73 73 73]\n",
      "Epoch: 1827, loss: 4.637, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 1828, loss: 4.681, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 1829, loss: 4.688, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 1830, loss: 4.705, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 1831, loss: 4.580, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 1832, loss: 4.515, training accuracy: 0.00%\n",
      "[52 52 52 52 52 52 52 52 52 52]\n",
      "Epoch: 1833, loss: 4.685, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1834, loss: 4.768, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1835, loss: 4.594, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1836, loss: 4.948, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1837, loss: 4.671, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1838, loss: 4.833, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1839, loss: 4.761, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1840, loss: 4.695, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1841, loss: 4.588, training accuracy: 10.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1842, loss: 4.925, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1843, loss: 4.769, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1844, loss: 4.776, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1845, loss: 4.694, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1846, loss: 4.598, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1847, loss: 4.603, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1848, loss: 4.791, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1849, loss: 4.657, training accuracy: 0.00%\n",
      "[67 67 67 67 67 67 67 67 67 67]\n",
      "Epoch: 1850, loss: 4.764, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1851, loss: 4.809, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1852, loss: 4.682, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1853, loss: 4.644, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1854, loss: 4.679, training accuracy: 0.00%\n",
      "[85 85 85 85 85 85 85 85 85 85]\n",
      "Epoch: 1855, loss: 4.557, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1856, loss: 4.604, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1857, loss: 4.591, training accuracy: 10.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1858, loss: 4.802, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1859, loss: 4.650, training accuracy: 10.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1860, loss: 4.789, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1861, loss: 4.650, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1862, loss: 4.665, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1863, loss: 4.574, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1864, loss: 4.624, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1865, loss: 4.724, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1866, loss: 4.646, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1867, loss: 4.722, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1868, loss: 4.484, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1869, loss: 4.629, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1870, loss: 4.600, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1871, loss: 4.610, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1872, loss: 4.692, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1873, loss: 4.854, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1874, loss: 4.617, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1875, loss: 4.611, training accuracy: 0.00%\n",
      "[33 33 33 33 33 33 33 33 33 33]\n",
      "Epoch: 1876, loss: 4.669, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 1877, loss: 4.635, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 1878, loss: 4.759, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 1879, loss: 4.433, training accuracy: 0.00%\n",
      "[37 37 37 37 37 37 37 37 37 37]\n",
      "Epoch: 1880, loss: 4.632, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1881, loss: 4.487, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1882, loss: 4.608, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1883, loss: 4.745, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1884, loss: 4.717, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1885, loss: 4.675, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1886, loss: 4.662, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1887, loss: 4.757, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1888, loss: 4.841, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1889, loss: 4.716, training accuracy: 0.00%\n",
      "[69 69 69 69 69 69 69 69 69 69]\n",
      "Epoch: 1890, loss: 4.601, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1891, loss: 4.826, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1892, loss: 4.682, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1893, loss: 4.739, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1894, loss: 4.709, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1895, loss: 4.717, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1896, loss: 4.603, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1897, loss: 4.749, training accuracy: 0.00%\n",
      "[102 102 102 102 102 102 102 102 102 102]\n",
      "Epoch: 1898, loss: 4.496, training accuracy: 0.00%\n",
      "[17 17 17 17 17 17 17 17 17 17]\n",
      "Epoch: 1899, loss: 4.564, training accuracy: 0.00%\n",
      "[17 17 17 17 17 17 17 17 17 17]\n",
      "Epoch: 1900, loss: 4.624, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1901, loss: 4.897, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1902, loss: 4.671, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1903, loss: 4.460, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1904, loss: 4.806, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1905, loss: 4.571, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1906, loss: 4.743, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1907, loss: 4.834, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1908, loss: 4.701, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1909, loss: 4.697, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1910, loss: 4.750, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1911, loss: 4.682, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1912, loss: 4.627, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1913, loss: 4.716, training accuracy: 0.00%\n",
      "[79 79 79 79 79 79 79 79 79 79]\n",
      "Epoch: 1914, loss: 4.606, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1915, loss: 4.714, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1916, loss: 4.634, training accuracy: 10.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1917, loss: 4.913, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1918, loss: 4.578, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1919, loss: 4.633, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1920, loss: 4.886, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1921, loss: 4.544, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1922, loss: 4.693, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1923, loss: 4.585, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1924, loss: 4.649, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1925, loss: 4.615, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1926, loss: 4.717, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1927, loss: 4.647, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1928, loss: 4.715, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1929, loss: 4.673, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1930, loss: 4.610, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1931, loss: 4.610, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1932, loss: 4.671, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1933, loss: 4.618, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1934, loss: 4.617, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1935, loss: 4.617, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1936, loss: 4.824, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1937, loss: 4.591, training accuracy: 10.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1938, loss: 4.690, training accuracy: 10.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1939, loss: 4.743, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1940, loss: 4.729, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1941, loss: 4.564, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1942, loss: 4.607, training accuracy: 0.00%\n",
      "[35 35 35 35 35 35 35 35 35 35]\n",
      "Epoch: 1943, loss: 4.640, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1944, loss: 4.694, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1945, loss: 4.618, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1946, loss: 4.659, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1947, loss: 4.666, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1948, loss: 4.708, training accuracy: 0.00%\n",
      "[11 11 11 11 11 11 11 11 11 11]\n",
      "Epoch: 1949, loss: 4.695, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1950, loss: 4.778, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1951, loss: 4.594, training accuracy: 10.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1952, loss: 4.757, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1953, loss: 4.506, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1954, loss: 4.712, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1955, loss: 4.556, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1956, loss: 4.685, training accuracy: 0.00%\n",
      "[48 48 48 48 48 48 48 48 48 48]\n",
      "Epoch: 1957, loss: 4.698, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 1958, loss: 4.721, training accuracy: 0.00%\n",
      "[88 88 88 88 88 88 88 88 88 88]\n",
      "Epoch: 1959, loss: 4.488, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1960, loss: 4.840, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1961, loss: 4.496, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1962, loss: 4.803, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1963, loss: 4.805, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1964, loss: 4.640, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1965, loss: 4.693, training accuracy: 0.00%\n",
      "[13 13 13 13 13 13 13 13 13 13]\n",
      "Epoch: 1966, loss: 4.480, training accuracy: 0.00%\n",
      "[39 39 39 39 39 39 39 39 39 39]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6568aea63bb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmerged_summary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmerged_summary_operation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1110\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1284\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1286\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1287\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1275\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1277\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1365\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run the training\n",
    "epochs = training_epochs\n",
    "results = pd.DataFrame(columns=['loss','accuracy'])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    sess.run(training_init_op)\n",
    "    train_summary_writer = tf.summary.FileWriter('./tmp/train',sess.graph)\n",
    "    test_summary_writer = tf.summary.FileWriter('./tmp/test')\n",
    "    for i in range(epochs):\n",
    "        log,lab,pr = sess.run([logits,labels_y,pred])\n",
    "        print(np.argmax(log,1))\n",
    "        l, _, acc,merged_summary = sess.run([loss, optimizer, accuracy,merged_summary_operation])\n",
    "        \n",
    "        print(\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\".format(i+1, l, acc * 100))\n",
    "        '''\n",
    "        # now setup the validation run\n",
    "        test_iters = 1\n",
    "        # re-initialize the iterator, but this time with validation data\n",
    "        sess.run(test_init_op)\n",
    "        test_l, test_acc = sess.run([loss, accuracy])\n",
    "        print(\"Epoch: {}, test loss: {:.3f}, test accuracy: {:.2f}%\".format(i+1, test_l, test_acc * 100))\n",
    "        '''\n",
    "        results.loc[i] = [l,acc]\n",
    "        train_summary_writer.add_summary(merged_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(log,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(lab,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
