\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{bailador2011analysis}
\citation{sanmorino2012survey,galbally2015line}
\citation{jeon2012system,sesa2012information,malik20183dairsig}
\citation{malik20183dairsig}
\citation{jeon2012system}
\citation{moon2017air}
\citation{moon2017air}
\citation{shi2017smart,pokkunuru2018neuralwave}
\citation{toh100,toh2018learning,toh2018analytic,toh2018gradient}
\citation{weinberger2006distance}
\citation{hoffer2015deep}
\citation{chen2017beyond,cheng2016person,ding2015deep,schroff2015facenet,wang2016joint}
\citation{hermans2017defense}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related works}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Triplet network}{1}{subsection.2.1}\protected@file@percent }
\citation{schroff2015facenet}
\citation{cheng2016person,ding2015deep,wang2016joint}
\citation{schroff2015facenet}
\citation{toh100,toh2018learning,toh2018analytic,toh2018gradient}
\citation{goodfellow2016deep}
\citation{toh2018learning,toh2018gradient}
\citation{toh2018gradient}
\citation{hoffer2015deep}
\citation{toh2018learning,toh2018gradient}
\citation{schroff2015facenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Kernel and the range space learning\nonbreakingspace \citep  {toh100,toh2018learning,toh2018analytic,toh2018gradient}}{2}{subsection.2.2}\protected@file@percent }
\newlabel{kar}{{2.2}{2}{Kernel and the range space learning~\cite {toh100,toh2018learning,toh2018analytic,toh2018gradient}}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed System}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Triplet mining using kernel and the range space learning}{2}{subsection.3.1}\protected@file@percent }
\newlabel{pos}{{4}{2}{Triplet mining using kernel and the range space learning}{equation.3.4}{}}
\newlabel{neg}{{5}{2}{Triplet mining using kernel and the range space learning}{equation.3.5}{}}
\citation{lecun1998gradient}
\citation{hoffer2015deep}
\citation{moon2017air}
\citation{toh2003fingerprint,toh2008between}
\citation{koch2015siamese}
\citation{hoffer2015deep}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An overview of the proposed system\relax }}{3}{figure.caption.5}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig1}{{1}{3}{An overview of the proposed system\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}ConvNet structure}{3}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}The triplet loss}{3}{subsection.3.3}\protected@file@percent }
\newlabel{triplet}{{6}{3}{The triplet loss}{equation.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Dataset}{3}{subsection.4.1}\protected@file@percent }
\citation{toh2018analytic}
\bibstyle{ACM-Reference-Format}
\bibdata{bib_conf}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The network structure of KAR space learning\relax }}{4}{table.caption.6}\protected@file@percent }
\newlabel{tab2}{{1}{4}{The network structure of KAR space learning\relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Experimental settings}{4}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Performance evaluation:}{4}{subsubsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Network Structure and Parameter Settings:}{4}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The structure of ConvNet model. For the convolution layer, kernel is specified as (m$\times $m) sized filter $\times $ \# of filters / \# of stride. For the max-pooling layer, (p$\times $p) sized pooling windows / \# of stride. The input sizes are denoted as rows $\times $ cols $\times $ \# of filters\relax }}{4}{table.caption.7}\protected@file@percent }
\newlabel{tab1}{{2}{4}{The structure of ConvNet model. For the convolution layer, kernel is specified as (m$\times $m) sized filter $\times $ \# of filters / \# of stride. For the max-pooling layer, (p$\times $p) sized pooling windows / \# of stride. The input sizes are denoted as rows $\times $ cols $\times $ \# of filters\relax }{table.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Results and discussion}{4}{subsection.4.3}\protected@file@percent }
\bibcite{bailador2011analysis}{{1}{2011}{{Bailador et~al\unhbox \voidb@x \hbox {.}}}{{Bailador, Sanchez-Avila, Guerra-Casanova, and de~Santos~Sierra}}}
\bibcite{chen2017beyond}{{2}{2017}{{Chen et~al\unhbox \voidb@x \hbox {.}}}{{Chen, Chen, Zhang, and Huang}}}
\bibcite{cheng2016person}{{3}{2016}{{Cheng et~al\unhbox \voidb@x \hbox {.}}}{{Cheng, Gong, Zhou, Wang, and Zheng}}}
\bibcite{ding2015deep}{{4}{2015}{{Ding et~al\unhbox \voidb@x \hbox {.}}}{{Ding, Lin, Wang, and Chao}}}
\bibcite{galbally2015line}{{5}{2015}{{Galbally et~al\unhbox \voidb@x \hbox {.}}}{{Galbally, Diaz-Cabrera, Ferrer, Gomez-Barrero, Morales, and Fierrez}}}
\bibcite{goodfellow2016deep}{{6}{2016}{{Goodfellow et~al\unhbox \voidb@x \hbox {.}}}{{Goodfellow, Bengio, and Courville}}}
\bibcite{hermans2017defense}{{7}{2017}{{Hermans et~al\unhbox \voidb@x \hbox {.}}}{{Hermans, Beyer, and Leibe}}}
\bibcite{hoffer2015deep}{{8}{2015}{{Hoffer and Ailon}}{{Hoffer and Ailon}}}
\bibcite{jeon2012system}{{9}{2012}{{Jeon et~al\unhbox \voidb@x \hbox {.}}}{{Jeon, Oh, and Toh}}}
\bibcite{koch2015siamese}{{10}{2015}{{Koch et~al\unhbox \voidb@x \hbox {.}}}{{Koch, Zemel, and Salakhutdinov}}}
\bibcite{lecun1998gradient}{{11}{1998}{{LeCun et~al\unhbox \voidb@x \hbox {.}}}{{LeCun, Bottou, Bengio, Haffner, et~al\unhbox \voidb@x \hbox {.}}}}
\bibcite{malik20183dairsig}{{12}{2018}{{Malik et~al\unhbox \voidb@x \hbox {.}}}{{Malik, Elhayek, Ahmed, Shafait, Malik, and Stricker}}}
\bibcite{moon2017air}{{13}{2017}{{Moon et~al\unhbox \voidb@x \hbox {.}}}{{Moon, Jang, Oh, and Toh}}}
\bibcite{pokkunuru2018neuralwave}{{14}{2018}{{Pokkunuru et~al\unhbox \voidb@x \hbox {.}}}{{Pokkunuru, Jakkala, Bhuyan, Wang, and Sun}}}
\bibcite{sanmorino2012survey}{{15}{2012}{{Sanmorino and Yazid}}{{Sanmorino and Yazid}}}
\bibcite{schroff2015facenet}{{16}{2015}{{Schroff et~al\unhbox \voidb@x \hbox {.}}}{{Schroff, Kalenichenko, and Philbin}}}
\bibcite{sesa2012information}{{17}{2012}{{Sesa-Nogueras et~al\unhbox \voidb@x \hbox {.}}}{{Sesa-Nogueras, Faundez-Zanuy, and Mekyska}}}
\bibcite{shi2017smart}{{18}{2017}{{Shi et~al\unhbox \voidb@x \hbox {.}}}{{Shi, Liu, Liu, and Chen}}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance benchmarking with respect to the best EER (\%) averaged from five runs of two-fold cross-validation test on Wi-Fi CSI signature dataset\relax }}{5}{table.caption.8}\protected@file@percent }
\newlabel{tab3}{{3}{5}{Performance benchmarking with respect to the best EER (\%) averaged from five runs of two-fold cross-validation test on Wi-Fi CSI signature dataset\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{5}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{5}{section*.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces (a) shows the Receiver Operating Characteristic(ROC) Curve and (b) shows the normalized training loss curve of the deep learning based methods\relax }}{5}{figure.caption.9}\protected@file@percent }
\newlabel{fig2}{{2}{5}{(a) shows the Receiver Operating Characteristic(ROC) Curve and (b) shows the normalized training loss curve of the deep learning based methods\relax }{figure.caption.9}{}}
\bibcite{toh2018analytic}{{19}{2018a}{{Toh}}{{Toh}}}
\bibcite{toh2003fingerprint}{{20}{2003}{{Toh}}{{Toh}}}
\bibcite{toh100}{{21}{2018b}{{Toh}}{{Toh}}}
\bibcite{toh2018learning}{{22}{2018c}{{Toh}}{{Toh}}}
\bibcite{toh2008between}{{23}{2008}{{Toh and Eng}}{{Toh and Eng}}}
\bibcite{toh2018gradient}{{24}{2018}{{Toh et~al\unhbox \voidb@x \hbox {.}}}{{Toh, Lin, Li, Oh, and Sun}}}
\bibcite{wang2016joint}{{25}{2016}{{Wang et~al\unhbox \voidb@x \hbox {.}}}{{Wang, Zuo, Lin, Zhang, and Zhang}}}
\bibcite{weinberger2006distance}{{26}{2006}{{Weinberger et~al\unhbox \voidb@x \hbox {.}}}{{Weinberger, Blitzer, and Saul}}}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{4.185pt}
\newlabel{tocindent2}{10.35pt}
\newlabel{tocindent3}{18.198pt}
\newlabel{TotPages}{{6}{6}{}{page.6}{}}
