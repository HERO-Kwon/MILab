{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herok\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows\n",
    "file_path = 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout'\n",
    "\n",
    "# For Linux\n",
    "# file_path = '/home/hero/Matlab_Drive/Data/ORLDB'\n",
    "\n",
    "file_list = os.listdir(file_path)\n",
    "file_list_data = [s for s in file_list if not \"_idx.npy\" in s]\n",
    "file_list_idx = [s for s in file_list if \"_idx.npy\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '%s/*.npy'%file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8_idx.npy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(file_path)\n",
    "file_list_data = [s for s in file_list if not \"_idx.npy\" in s]\n",
    "file_list_idx = [s for s in file_list if \"_idx.npy\" in s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset_1.npy',\n",
       " 'Dataset_2.npy',\n",
       " 'Dataset_3.npy',\n",
       " 'Dataset_4.npy',\n",
       " 'Dataset_5.npy',\n",
       " 'Dataset_6.npy',\n",
       " 'Dataset_7.npy',\n",
       " 'Dataset_8.npy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(file_path)\n",
    "file_list_data = [os.path.join(file_path,s) for s in file_list if not \"_idx.npy\" in s]\n",
    "file_list_idx = [os.path.join(file_path,s) for s in file_list if \"_idx.npy\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8.npy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(file_list_data,file_list_idx,test_size=0.2,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5.npy']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8.npy']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5_idx.npy']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8_idx.npy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(x_train,shuffle=False,name='filename_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.data_flow_ops.FIFOQueue at 0x17092499e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reader\n",
    "reader = tf.WholeFileReader()\n",
    "key,value = reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-33-25c51a2f7f91>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-25c51a2f7f91>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    with tf.Session() as sess:\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "py_func() missing 1 required positional argument: 'Tout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-2d8c62f0527d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilenames_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m dataset = dataset.map(\n\u001b[1;32m---> 11\u001b[1;33m     lambda filename_data,filename_idx: tuple(tf.py_func(\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mread_npy_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     ))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \"\"\"\n\u001b[0;32m    850\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   1837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_map_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_variant_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    482\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[1;31m# Adds this function into 'g'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    334\u001b[0m       \u001b[1;31m# Call func and gather the output tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemp_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m       \u001b[1;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mtf_map_func\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   1800\u001b[0m           input_dataset.output_classes)\n\u001b[0;32m   1801\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_unpack_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1803\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-2d8c62f0527d>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(filename_data, filename_idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m dataset = dataset.map(\n\u001b[0;32m     11\u001b[0m     lambda filename_data,filename_idx: tuple(tf.py_func(\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mread_npy_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     ))\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: py_func() missing 1 required positional argument: 'Tout'"
     ]
    }
   ],
   "source": [
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "filenames_data = x_train\n",
    "filenames_idx = y_train\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_idx))\n",
    "dataset = dataset.map(\n",
    "    lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "        read_npy_file,[filename_data,filename_idx]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (<unknown>, <unknown>), types: (tf.float32, tf.uint8)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Session has been closed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run() missing 1 required positional argument: 'fetches'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-9485da3e31c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: run() missing 1 required positional argument: 'fetches'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    for i in range(100):\n",
    "        print(sess.run())\n",
    "    coord.request_stop()\n",
    "    coord.join(threads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'IteratorGetNext_1:0' shape=(?,) dtype=int64>,\n",
       " <tf.Tensor 'IteratorGetNext_1:1' shape=(?,) dtype=int64>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-0fbf84b53840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfilenames_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilenames_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m dataset = dataset.map(\n\u001b[0;32m     12\u001b[0m     lambda filename_data,filename_idx: tuple(tf.py_func(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames_labels' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "filenames_data = x_train\n",
    "filenames_idx = y_train\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_labels))\n",
    "dataset = dataset.map(\n",
    "    lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "        read_npy_file,[filename_data,filename_idx],[tf.float32,tf.uint8]\n",
    "    ))\n",
    ")\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(dataset.outpyt_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) "
     ]
    }
   ],
   "source": [
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "filenames_data = x_train\n",
    "filenames_idx = y_train\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_idx))\n",
    "dataset = dataset.map(\n",
    "    lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "        read_npy_file,[filename_data,filename_idx],[tf.float64,tf.float64]\n",
    "    ))\n",
    ")\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(1):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value[1].shape}\", end=\" \")    # 1 2 3 ... 10\t   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6, 30, 500)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(value[1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "def make_dataset(filenames_data,filenames_idx):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_idx))\n",
    "    dataset = dataset.map(\n",
    "        lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "            read_npy_file,[filename_data,filename_idx],[tf.double,tf.double]\n",
    "        ))\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(x_train,y_train)\n",
    "test_dataset = make_dataset(x_test,y_test)\n",
    "\n",
    "iterator_train = train_dataset.make_one_shot_iterator()\n",
    "iterator_test = test_dataset.make_one_shot_iterator()\n",
    "next_element = iterator_test.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6, 30, 500) (1000, 6, 30, 500) End of Dataset\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            value = sess.run(next_element)\n",
    "            print(f\"{value[0].shape}\", end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of Dataset\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(value[1].squeeze(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype float64 for Tensor with dtype float32: 'Tensor(\"random_normal_13:0\", shape=(128, 100), dtype=float32)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-81334b61bc1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mexpected_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape, constraint)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           self._initial_value = ops.convert_to_tensor(\n\u001b[1;32m--> 355\u001b[1;33m               initial_value, name=\"initial_value\", dtype=dtype)\n\u001b[0m\u001b[0;32m    356\u001b[0m           \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m   1012\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    945\u001b[0m     raise ValueError(\n\u001b[0;32m    946\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m    948\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype float64 for Tensor with dtype float32: 'Tensor(\"random_normal_13:0\", shape=(128, 100), dtype=float32)'"
     ]
    }
   ],
   "source": [
    "## Network\n",
    "learning_rate = 0.001\n",
    "n_input = 6*30\n",
    "n_step  = 500\n",
    "n_class = 100\n",
    "total_batch = 6\n",
    "n_hidden = 128\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float64,[None,n_step,n_input])\n",
    "Y = tf.placeholder(tf.float64,[None,n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden,n_class]),dtype='float64')\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden,reuse=tf.AUTO_REUSE)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell,X,dtype=tf.float64)\n",
    "\n",
    "outputs = tf.transpose(outputs,[1,0,2])\n",
    "outputs = outputs[-1]\n",
    "\n",
    "model = tf.matmul(outputs,W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=model,labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.float32(np.load(filename_data.decode()))\n",
    "    idx_read = np.float32(np.load(filename_idx.decode()))\n",
    "    return data_read,idx_read\n",
    "\n",
    "def make_dataset(filenames_data,filenames_idx):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_idx))\n",
    "    dataset = dataset.map(\n",
    "        lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "            read_npy_file,[filename_data,filename_idx],[tf.double,tf.double]\n",
    "        ))\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(x_train,y_train)\n",
    "test_dataset = make_dataset(x_test,y_test)\n",
    "\n",
    "iterator_train = train_dataset.make_one_shot_iterator()\n",
    "iterator_test = test_dataset.make_one_shot_iterator()\n",
    "next_element = iterator_train.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-132-ce4a4948ce2d>:25: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Network\n",
    "learning_rate = 0.001\n",
    "n_input = 6*30\n",
    "n_step  = 500\n",
    "n_class = 100\n",
    "total_batch = 6\n",
    "n_hidden = 128\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,n_step,n_input])\n",
    "Y = tf.placeholder(tf.float32,[None,n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden,n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell,X,dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs,[1,0,2])\n",
    "outputs = outputs[-1]\n",
    "\n",
    "model = tf.matmul(outputs,W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=model,labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-7652584cf201>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mbatch_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             _,cost_val = sess.run([optimizer,cost],\n\u001b[0;32m      8\u001b[0m             feed_dict = {X:batch_xs,Y:batch_ys})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_xs' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        try:\n",
    "            batch_xs = batch_xs.reshape((batch_size,n_step,n_input))\n",
    "            _,cost_val = sess.run([optimizer,cost],\n",
    "            feed_dict = {X:batch_xs,Y:batch_ys})\n",
    "\n",
    "            total_cost += cost_val\n",
    "    \n",
    "            \n",
    "            #value = sess.run(next_element)\n",
    "            #print(f\"{value[1].shape}\", end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of Dataset\")\n",
    "        print('Epoch:','%04d' % (epoch+1),\n",
    "        'Avg.cost = ',':.3f'.format(total_cost / total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-292149a21d1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_element\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mbatch_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             _,cost_val = sess.run([optimizer,cost],\n\u001b[0;32m      9\u001b[0m             feed_dict = {X:batch_xs,Y:batch_ys})\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        try:\n",
    "            batch_xs,batch_ys = next_element\n",
    "            batch_xs = batch_xs.reshape((batch_size,n_step,n_input))\n",
    "            _,cost_val = sess.run([optimizer,cost],\n",
    "            feed_dict = {X:batch_xs,Y:batch_ys})\n",
    "\n",
    "            total_cost += cost_val\n",
    "    \n",
    "            \n",
    "            #value = sess.run(next_element)\n",
    "            #print(f\"{value[1].shape}\", end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of Dataset\")\n",
    "        print('Epoch:','%04d' % (epoch+1),\n",
    "        'Avg.cost = ',':.3f'.format(total_cost / total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"Reshape:0\", shape=(1000, 500, 180), dtype=float64) which was passed to the feed with key Tensor(\"Placeholder:0\", shape=(?, 500, 180), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-71a46385af04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mbatch_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             _,cost_val = sess.run([optimizer,cost],\n\u001b[1;32m----> 9\u001b[1;33m             feed_dict = {X:batch_xs,Y:batch_ys})\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mtotal_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcost_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1084\u001b[0m                             \u001b[1;34m'For reference, the tensor object was '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_val\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' which was passed to the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1086\u001b[1;33m                             'feed with key ' + str(feed) + '.')\n\u001b[0m\u001b[0;32m   1087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m           \u001b[0msubfeed_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The value of a feed cannot be a tf.Tensor object. Acceptable feed values include Python scalars, strings, lists, numpy ndarrays, or TensorHandles.For reference, the tensor object was Tensor(\"Reshape:0\", shape=(1000, 500, 180), dtype=float64) which was passed to the feed with key Tensor(\"Placeholder:0\", shape=(?, 500, 180), dtype=float32)."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        try:\n",
    "            batch_xs,batch_ys = next_element\n",
    "            batch_xs = tf.reshape(batch_xs,(batch_size,n_step,n_input))\n",
    "            _,cost_val = sess.run([optimizer,cost],\n",
    "            feed_dict = {X:batch_xs,Y:batch_ys})\n",
    "\n",
    "            total_cost += cost_val\n",
    "    \n",
    "            \n",
    "            #value = sess.run(next_element)\n",
    "            #print(f\"{value[1].shape}\", end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of Dataset\")\n",
    "        print('Epoch:','%04d' % (epoch+1),\n",
    "        'Avg.cost = ',':.3f'.format(total_cost / total_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-96238ff1f411>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_handle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0mbatch_xs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             _,cost_val = sess.run([optimizer,cost],\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(x_train,y_train)\n",
    "test_dataset = make_dataset(x_test,y_test)\n",
    "\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(\n",
    "    handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "\n",
    "next_element = iterator_train.get_next()\n",
    "iterator_train = train_dataset.make_one_shot_iterator()\n",
    "iterator_test = test_dataset.make_one_shot_iterator()\n",
    "\n",
    "\n",
    "## Network\n",
    "learning_rate = 0.001\n",
    "n_input = 6*30\n",
    "n_step  = 500\n",
    "n_class = 100\n",
    "total_batch = 6\n",
    "n_hidden = 128\n",
    "batch_size = 1000\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,n_step,n_input])\n",
    "Y = tf.placeholder(tf.float32,[None,n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden,n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell,X,dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs,[1,0,2])\n",
    "outputs = outputs[-1]\n",
    "\n",
    "model = tf.matmul(outputs,W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=model,labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    training_handle = sess.run(iterator_train.string_handle())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_cost = 0\n",
    "    for i in range(total_batch):\n",
    "        try:\n",
    "            batch_xs,batch_ys = training_handle\n",
    "            batch_xs = tf.reshape(batch_xs,(batch_size,n_step,n_input))\n",
    "            _,cost_val = sess.run([optimizer,cost],\n",
    "            feed_dict = {X:batch_xs,Y:batch_ys})\n",
    "\n",
    "            total_cost += cost_val\n",
    "    \n",
    "            \n",
    "            #value = sess.run(next_element)\n",
    "            #print(f\"{value[1].shape}\", end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of Dataset\")\n",
    "        print('Epoch:','%04d' % (epoch+1),\n",
    "        'Avg.cost = ',':.3f'.format(total_cost / total_batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"\\n,/job:localhost/replica:0/task:0/device:CPU:0\\x12\\tlocalhost\\x1a\\x13_21_OneShotIterator \\x89\\xfd\\x96\\xfc\\xe0\\xa1\\xd0\\xe25*9class tensorflow::`anonymous namespace'::IteratorResource\""
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
