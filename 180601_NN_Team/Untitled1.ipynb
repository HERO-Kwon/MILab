{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\herok\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows\n",
    "file_path = 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout'\n",
    "\n",
    "# For Linux\n",
    "# file_path = '/home/hero/Matlab_Drive/Data/ORLDB'\n",
    "\n",
    "file_list = os.listdir(file_path)\n",
    "file_list_data = [s for s in file_list if not \"_idx.npy\" in s]\n",
    "file_list_idx = [s for s in file_list if \"_idx.npy\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '%s/*.npy'%file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8_idx.npy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(file_path)\n",
    "file_list_data = [s for s in file_list if not \"_idx.npy\" in s]\n",
    "file_list_idx = [s for s in file_list if \"_idx.npy\" in s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset_1.npy',\n",
       " 'Dataset_2.npy',\n",
       " 'Dataset_3.npy',\n",
       " 'Dataset_4.npy',\n",
       " 'Dataset_5.npy',\n",
       " 'Dataset_6.npy',\n",
       " 'Dataset_7.npy',\n",
       " 'Dataset_8.npy']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(file_path)\n",
    "file_list_data = [os.path.join(file_path,s) for s in file_list if not \"_idx.npy\" in s]\n",
    "file_list_idx = [os.path.join(file_path,s) for s in file_list if \"_idx.npy\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8.npy']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(file_list_data,file_list_idx,test_size=0.2,random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5.npy']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8.npy']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_4_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_2_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_6_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_3_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_1_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_5_idx.npy']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_7_idx.npy',\n",
       " 'D:\\\\Matlab_Drive\\\\Data\\\\WIFI\\\\180_100_DCout\\\\Dataset_8_idx.npy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer(x_train,shuffle=False,name='filename_queue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.data_flow_ops.FIFOQueue at 0x17092499e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reader\n",
    "reader = tf.WholeFileReader()\n",
    "key,value = reader.read(filename_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-33-25c51a2f7f91>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-25c51a2f7f91>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    with tf.Session() as sess:\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "py_func() missing 1 required positional argument: 'Tout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-2d8c62f0527d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilenames_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m dataset = dataset.map(\n\u001b[1;32m---> 11\u001b[1;33m     lambda filename_data,filename_idx: tuple(tf.py_func(\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mread_npy_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     ))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \"\"\"\n\u001b[0;32m    850\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   1837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_map_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_variant_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[1;34m(self, g)\u001b[0m\n\u001b[0;32m    482\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[1;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[1;31m# Adds this function into 'g'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    334\u001b[0m       \u001b[1;31m# Call func and gather the output tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtemp_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m       \u001b[1;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mtf_map_func\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   1800\u001b[0m           input_dataset.output_classes)\n\u001b[0;32m   1801\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_unpack_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1803\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-2d8c62f0527d>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(filename_data, filename_idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m dataset = dataset.map(\n\u001b[0;32m     11\u001b[0m     lambda filename_data,filename_idx: tuple(tf.py_func(\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mread_npy_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfilename_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     ))\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: py_func() missing 1 required positional argument: 'Tout'"
     ]
    }
   ],
   "source": [
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "filenames_data = x_train\n",
    "filenames_idx = y_train\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_idx))\n",
    "dataset = dataset.map(\n",
    "    lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "        read_npy_file,[filename_data,filename_idx]\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (<unknown>, <unknown>), types: (tf.float32, tf.uint8)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Session has been closed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run() missing 1 required positional argument: 'fetches'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-9485da3e31c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: run() missing 1 required positional argument: 'fetches'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    for i in range(100):\n",
    "        print(sess.run())\n",
    "    coord.request_stop()\n",
    "    coord.join(threads) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_dataset = tf.data.Dataset.range(100)\n",
    "dec_dataset = tf.data.Dataset.range(0, -100, -1)\n",
    "dataset = tf.data.Dataset.zip((inc_dataset, dec_dataset))\n",
    "batched_dataset = dataset.batch(4)\n",
    "\n",
    "iterator = batched_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'IteratorGetNext_1:0' shape=(?,) dtype=int64>,\n",
       " <tf.Tensor 'IteratorGetNext_1:1' shape=(?,) dtype=int64>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n",
      "(TensorShape([]), TensorShape([]))\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-0fbf84b53840>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfilenames_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilenames_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m dataset = dataset.map(\n\u001b[0;32m     12\u001b[0m     lambda filename_data,filename_idx: tuple(tf.py_func(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames_labels' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "filenames_data = x_train\n",
    "filenames_idx = y_train\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_labels))\n",
    "dataset = dataset.map(\n",
    "    lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "        read_npy_file,[filename_data,filename_idx],[tf.float32,tf.uint8]\n",
    "    ))\n",
    ")\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        value = sess.run(next_element)\n",
    "        print(dataset.outpyt_shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1) "
     ]
    }
   ],
   "source": [
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "filenames_data = x_train\n",
    "filenames_idx = y_train\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_idx))\n",
    "dataset = dataset.map(\n",
    "    lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "        read_npy_file,[filename_data,filename_idx],[tf.float64,tf.float64]\n",
    "    ))\n",
    ")\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(1):\n",
    "        value = sess.run(next_element)\n",
    "        print(f\"{value[1].shape}\", end=\" \")    # 1 2 3 ... 10\t   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6, 30, 500)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(value[1][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_npy_file(filename_data,filename_idx):\n",
    "    data_read = np.load(filename_data.decode())\n",
    "    idx_read = np.load(filename_idx.decode())\n",
    "    return data_read,idx_read\n",
    "\n",
    "def make_dataset(filenames_data,filenames_idx):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames_data,filenames_idx))\n",
    "    dataset = dataset.map(\n",
    "        lambda filename_data,filename_idx: tuple(tf.py_func(\n",
    "            read_npy_file,[filename_data,filename_idx],[tf.double,tf.double]\n",
    "        ))\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(x_train,y_train)\n",
    "test_dataset = make_dataset(x_test,y_test)\n",
    "\n",
    "iterator_train = train_dataset.make_one_shot_iterator()\n",
    "iterator_test = test_dataset.make_one_shot_iterator()\n",
    "next_element = iterator_test.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6, 30, 500) (1000, 6, 30, 500) End of Dataset\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            value = sess.run(next_element)\n",
    "            print(f\"{value[0].shape}\", end=\" \")\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of Dataset\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
